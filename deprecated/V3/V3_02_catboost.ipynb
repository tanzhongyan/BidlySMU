{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d1cfa91a",
      "metadata": {},
      "source": [
        "# **SMU Course Bidding Prediction Using CatBoost V3**\n",
        "\n",
        "<div style=\"background-color:#DFFFD6; padding:12px; border-radius:5px; border: 1px solid #228B22;\">\n",
        "    \n",
        "  <h2 style=\"color:#006400;\">âœ… Looking to Implement This? âœ…</h2>\n",
        "  \n",
        "  <p>ðŸš€ **Get started quickly by using** <strong><a href=\"example_prediction.ipynb\">example_prediction.ipynb</a></strong>.</p>\n",
        "  \n",
        "  <ul>\n",
        "    <li>ðŸ“Œ **Pre-trained CatBoost model (`.cbm`) available for instant predictions.**</li>\n",
        "    <li>ðŸ”§ Includes **step-by-step instructions** for making predictions.</li>\n",
        "    <li>âš¡ Works **out-of-the-box**â€”just load the model and start predicting!</li>\n",
        "  </ul>\n",
        "\n",
        "  <h3>ðŸ”— ðŸ“Œ Next Steps:</h3>\n",
        "  <p>ðŸ‘‰ <a href=\"example_prediction.ipynb\"><strong>Go to Example Prediction Notebook</strong></a></p>\n",
        "\n",
        "</div>\n",
        "\n",
        "<h2><span style=\"color:red\">NOTE: use at your own descretion.</span></h2>\n",
        "\n",
        "### **Changes in V3**\n",
        "- Replaced `BidderCount` with `Before Process Vacancy` due to future dependent results like `After Process Vacancy` which is not available at prediction time.\n",
        "- Development of two models, one for `Median Bid Price` and `Min Bid Price`.\n",
        "- Refined model input to make ingesting data for prediction easier. No label encoding done for `Term` or `Round`.\n",
        "\n",
        "### **Objective**\n",
        "This notebook predicts the minimum bid required for courses in the SMU bidding system using a **CatBoost** regression model. Building on the insights gained from **V1 & V2**, this version incorporates **additional data columns** that may influence bid prices, improving the model's predictive power and interpretability. Additionally, this version creates two models:\n",
        "1. Median Bid Prices prediction\n",
        "2. Min Bid Prices prediction\n",
        "\n",
        "### **Key Enhancements in V3**\n",
        "\n",
        "**Learning from V1:**\n",
        "   - V1 relied solely on data readily available from BOSS.\n",
        "   - V2 incorporates **scraped data** from the BOSS Bidding website, adding features like:\n",
        "     - **Class timings** (days, start times, venues).\n",
        "     - **Exam schedules** (dates, start times, and days).\n",
        "     - **Grading basis** (e.g., graded or pass/fail).\n",
        "   - V2 additionally has outliers removed already in V2_03_SMU_Bidding_Preprocessing.ipynb\n",
        "\n",
        "**Learning from V2:**\n",
        "   - V2 had `BidderCount` which was future dependent. Although it was helpful in identifying supply demand, it may inadvertently provide poor results. Thus it is removed.\n",
        "   - Median Bid Prices may be easier to predict since it is more consistent than min bid prices. Thus, there may be value to using both to understand the estimated range of bids.\n",
        "\n",
        "\n",
        "\n",
        "### **Updated Dataset Columns**\n",
        "\n",
        "| **Column Name**                | **Description** |\n",
        "|--------------------------------|-----------------------------------------------------------|\n",
        "| **`Term`**                     | Academic term of the course (1, 2, 3A or 3B). |\n",
        "| **`Description`**              | Name of the course. |\n",
        "| **`Section`**                  | Course section identifier. |\n",
        "| **`Vacancy`**                  | Total available spots in the course. |\n",
        "| **`Before Process Vacancy`**   | Number of available spots **before** the bidding process. |\n",
        "| **`Instructor`**               | Name of the instructor. |\n",
        "| **`Grading Basis`**            | Type of grading (e.g., Graded, Pass/Fail). |\n",
        "| **`class1_day`**               | Day of the week for the first class session. |\n",
        "| **`class1_starttime`**         | Start time for the first class session. |\n",
        "| **`class1_venue`**             | Venue for the first class session. |\n",
        "| **`class2_day`**               | Day of the week for the second class session (if applicable). |\n",
        "| **`class2_starttime`**         | Start time for the second class session. |\n",
        "| **`class2_venue`**             | Venue for the second class session. |\n",
        "| **`class3_day`**               | Day of the week for the third class session (if applicable). |\n",
        "| **`class3_starttime`**         | Start time for the third class session. |\n",
        "| **`class3_venue`**             | Venue for the third class session. |\n",
        "| **`exam_day`**                 | Exam day of the week. |\n",
        "| **`exam_starttime`**           | Exam start time. |\n",
        "| **`AY`**                       | Academic year in which the course is offered. |\n",
        "| **`Incoming Freshman`**        | Whether the course is for incoming freshmen (`yes` or `no`). |\n",
        "| **`Incoming Exchange`**        | Whether the course is for incoming exchange students (`yes` or `no`). |\n",
        "| **`Round`**                    | Bidding round (1, 1A, 1B, 1C, 2, 2A). |\n",
        "| **`Window`**                   | Bidding window within the round (1, 2, 3, 4, 5). |\n",
        "| **`SubjectArea`**              | Subject area of the course (e.g., IS, ECON). |\n",
        "| **`CatalogueNo`**              | Course code (e.g., 453). |\n",
        "| **`exam_date`**                | Exam date (extracted from `exam_startdate`). |\n",
        "| **`exam_month`**               | Exam month (extracted from `exam_startdate`). |\n",
        "| **ðŸŽ¯ Target Variables ðŸŽ¯**      | **Predicted bid prices** |\n",
        "| **`Min Bid`**                  | Minimum bid price required for the course. |\n",
        "| **`Median Bid`**               | Median bid price required for the course. |\n",
        "\n",
        "### **Methodology**\n",
        "The notebook is structured as follows:\n",
        "\n",
        "1. **Data Preparation**:\n",
        "   - Loading and cleaning data.\n",
        "   - Standardizing data types.\n",
        "   - Splitting data into train and test sets.\n",
        "2. **Model Development**:\n",
        "   - Training a baseline CatBoost model with tuned parameters.\n",
        "   - Evaluating the model using **Mean Squared Log Error (MSLE)**.\n",
        "3. **Safety Factors and Analysis**:\n",
        "   - Experimenting with safety factors to improve TP rate.\n",
        "4. **Feature Importance**:\n",
        "   - Using CatBoost's internal feature importance metrics for insights.\n",
        "5. **Bootstrap-based Confidence Interval**:\n",
        "   - Provide sample prediction\n",
        "   - Retrain model on samples of training data and predict.\n",
        "6. **Conclusion**:\n",
        "   - Summarizing findings.\n",
        "   - Identifying next steps for improvement.\n",
        "\n",
        "### **Note**\n",
        "To run this notebook:\n",
        "- Ensure `catboost` is installed: `pip install catboost`.\n",
        "- Include the required dataset (`transformed_data_w_timings.csv`).\n",
        "\n",
        "This version aims to provide a more comprehensive analysis of factors influencing bid prices by leveraging richer data.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8520404",
      "metadata": {},
      "source": [
        "## **1. Data Preparation**\n",
        "\n",
        "### **1.1 Loading the Data**\n",
        "- Import necessary libraries.\n",
        "- Load the dataset and display its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "359f5072",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fa4dac95",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data\n",
        "# Load data without interpreting 'NA' as NaN\n",
        "data = pd.read_csv(\n",
        "    'transformed_data_w_timings_v3.csv',  # File path\n",
        "    keep_default_na=False              # Prevent automatic conversion of 'NA' to NaN\n",
        ")\n",
        "print(\"Data Shape:\", data.shape)\n",
        "display(data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbb1ffaf",
      "metadata": {},
      "source": [
        "### **1.2 Standardizing Data Types**\n",
        "- Ensure proper data types for numeric and categorical columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6b4df7be",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure proper data types for all columns\n",
        "def standardise_data_types(data):\n",
        "    # Ensure categorical columns are properly typed\n",
        "\n",
        "    categorical_cols = [\n",
        "        'Term','Description','Section',\n",
        "        'Instructor','Grading Basis','class1_day','class1_starttime','class1_venue',\n",
        "        'class2_day','class2_starttime','class2_venue','class3_day','class3_starttime',\n",
        "        'class3_venue','exam_startdate','exam_day','exam_starttime',\n",
        "        'Incoming Freshman','Incoming Exchange','Round','SubjectArea','CatalogueNo'\n",
        "    ]\n",
        "    for col in categorical_cols:\n",
        "        data[col] = data[col].astype('object')\n",
        "\n",
        "    # Convert date columns to datetime\n",
        "    data['exam_startdate'] = pd.to_datetime(data['exam_startdate'], errors='coerce')\n",
        "\n",
        "    # Extract year and month from `exam_startdate`\n",
        "    data['exam_date'] = data['exam_startdate'].dt.day\n",
        "    data['exam_month'] = data['exam_startdate'].dt.month\n",
        "\n",
        "    # Drop the original `exam_startdate` column\n",
        "    data = data.drop(columns=['exam_startdate'])\n",
        "\n",
        "    # Extract year and month from `exam_startdate`\n",
        "    data['exam_date'] = data['exam_date'].fillna(0).astype(int)\n",
        "    data['exam_month'] = data['exam_month'].fillna(0).astype(int)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Apply standardisation\n",
        "data = standardise_data_types(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4c34e95d",
      "metadata": {},
      "outputs": [],
      "source": [
        "data.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8b959eb",
      "metadata": {},
      "source": [
        "### **1.3 Train-Test Split**\n",
        "- Split the dataset into training (AY < 2024) and testing (AY = 2024, Term = 1 or 2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "90042691",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define test set as AY=2024 and Term=1\n",
        "test_mask = (data['AY'] == 2024) & (data['Term'].isin(['1', '2']))\n",
        "test_data = data[test_mask].copy()\n",
        "train_data = data[~test_mask].copy()\n",
        "\n",
        "print(\"Train shape:\", train_data.shape)\n",
        "print(\"Test shape:\", test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173c8f38",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "## **2. Model Development**\n",
        "\n",
        "### **2.1 Feature Selection**\n",
        "- Define features, target, and categorical variables.\n",
        "- Split into two target variables: `Min Bid` and `Median Bid`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "36f07abe",
      "metadata": {},
      "outputs": [],
      "source": [
        "target_min_bid = 'Min Bid'\n",
        "target_median_bid = 'Median Bid'\n",
        "\n",
        "features = [\n",
        "    'Term','Description','Section','Vacancy','Before Process Vacancy',\n",
        "    'Instructor','Grading Basis','class1_day','class1_starttime','class1_venue',\n",
        "    'class2_day','class2_starttime','class2_venue','class3_day','class3_starttime',\n",
        "    'class3_venue','exam_day','exam_starttime','AY',\n",
        "    'Incoming Freshman','Incoming Exchange','Round','Window','SubjectArea','CatalogueNo',\n",
        "    'exam_date', 'exam_month'\n",
        "]\n",
        "\n",
        "# Specify categorical features for CatBoost\n",
        "cat_features = [\n",
        "    'Term','Description','Section',\n",
        "    'Instructor','Grading Basis','class1_day','class1_starttime','class1_venue',\n",
        "    'class2_day','class2_starttime','class2_venue','class3_day','class3_starttime',\n",
        "    'class3_venue','exam_day','exam_starttime',\n",
        "    'Incoming Freshman','Incoming Exchange','Round','SubjectArea','CatalogueNo'\n",
        "]\n",
        "\n",
        "X_train = train_data[features]\n",
        "y_train_min_bid = train_data[target_min_bid]\n",
        "y_train_median_bid = train_data[target_median_bid]\n",
        "\n",
        "X_test = test_data[features]\n",
        "y_test_min_bid = test_data[target_min_bid]\n",
        "y_test_median_bid = test_data[target_median_bid]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e14959f",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "### **2.2 Training the Model**\n",
        "- Train a CatBoost model with tuned model parameters from V1.\n",
        "- Create two models:\n",
        "    1. `model_min_bid` - predict min prices.\n",
        "    2. `model_median_bid` - predict median prices."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "94a16840",
      "metadata": {},
      "source": [
        "#### model_min_bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d9078b58",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_min_bid = CatBoostRegressor(\n",
        "    bagging_temperature= 1,\n",
        "    random_strength=1,\n",
        "    depth=10,\n",
        "    learning_rate=0.1,\n",
        "    l2_leaf_reg=5,\n",
        "    iterations=1000,\n",
        "    cat_features=cat_features,\n",
        "    verbose=False)\n",
        "model_min_bid.fit(X_train, y_train_min_bid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d3772f5",
      "metadata": {},
      "source": [
        "#### model_median_bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "14434cd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_median_bid = CatBoostRegressor(\n",
        "    bagging_temperature= 1,\n",
        "    random_strength=1,\n",
        "    depth=10,\n",
        "    learning_rate=0.1,\n",
        "    l2_leaf_reg=5,\n",
        "    iterations=1000,\n",
        "    cat_features=cat_features,\n",
        "    verbose=False)\n",
        "model_median_bid.fit(X_train, y_train_median_bid)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f166878",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "### **2.3 Predictions and Metrics**\n",
        "**MSLE (Mean Squared Log Error)**\n",
        "- Measures relative error, penalising underestimations.\n",
        "\n",
        "**MAE (Mean Absolute Error)**\n",
        "- Measures absolute difference regardless of direction.\n",
        "\n",
        "**R Sqaure**\n",
        "- Proportion of variance in dependent variable explained by independent variables."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "708f49fe",
      "metadata": {},
      "source": [
        "#### model_min_bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "56972161",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions\n",
        "y_pred_min_bid = model_min_bid.predict(X_test)\n",
        "\n",
        "# Compute MSLE\n",
        "msle_value_min_bid = mean_squared_log_error(y_test_min_bid, y_pred_min_bid)\n",
        "print(\"Min Bid Model MSLE:\", msle_value_min_bid)\n",
        "\n",
        "# Compute MSLE\n",
        "mae_value_min_bid = mean_absolute_error(y_test_min_bid, y_pred_min_bid)\n",
        "print(\"Min Bid Model MAE:\", mae_value_min_bid)\n",
        "\n",
        "# Compute R2 score\n",
        "r2_value_min_bid = r2_score(y_test_min_bid, y_pred_min_bid)\n",
        "print(\"Min Bid Model R2:\", r2_value_min_bid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8d3e00d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate errors\n",
        "errors_min_bid = y_pred_min_bid - y_test_min_bid\n",
        "\n",
        "# Compute mean and standard deviation of errors\n",
        "mean_error_min_bid = np.mean(errors_min_bid)\n",
        "std_error_min_bid = np.std(errors_min_bid)\n",
        "\n",
        "# Compute 2.5th and 97.5th percentiles for the error distribution\n",
        "percentile_2_5_min_bid = np.percentile(errors_min_bid, 2.5)\n",
        "percentile_97_5_min_bid = np.percentile(errors_min_bid, 97.5)\n",
        "\n",
        "# Print values\n",
        "print(f\"2.5th percentile: {percentile_2_5_min_bid:.2f}\")\n",
        "print(f\"97.5th percentile: {percentile_97_5_min_bid:.2f}\")\n",
        "print(f\"Mean error: {mean_error_min_bid:.2f}\")\n",
        "print(f\"Std error: {std_error_min_bid:.2f}\")\n",
        "\n",
        "# Generate values for normal distribution curve\n",
        "x_values_min_bid = np.linspace(min(errors_min_bid), max(errors_min_bid), 100)\n",
        "y_values_min_bid = stats.norm.pdf(x_values_min_bid, mean_error_min_bid, std_error_min_bid) * len(errors_min_bid) * (max(errors_min_bid) - min(errors_min_bid)) / 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "964ba224",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot histogram of errors\n",
        "plt.hist(errors_min_bid, bins=50, alpha=0.7, color='blue', density=False, label=\"Error Distribution\")\n",
        "\n",
        "# Plot normal distribution curve\n",
        "plt.plot(x_values_min_bid, y_values_min_bid, color='black', linestyle='-', linewidth=2, label=\"Normal Approximation\")\n",
        "\n",
        "# Add vertical lines for standard deviations\n",
        "for i in range(1, 4):\n",
        "    plt.axvline(mean_error_min_bid + i * std_error_min_bid, color='green', linestyle='--', label=f'+{i} SD' if i == 1 else None)\n",
        "    plt.axvline(mean_error_min_bid - i * std_error_min_bid, color='green', linestyle='--', label=f'-{i} SD' if i == 1 else None)\n",
        "\n",
        "# Add vertical lines for percentiles\n",
        "plt.axvline(percentile_2_5_min_bid, color='orange', linestyle='--', label='2.5th Percentile')\n",
        "plt.axvline(percentile_97_5_min_bid, color='orange', linestyle='--', label='97.5th Percentile')\n",
        "\n",
        "# Labels and title\n",
        "plt.axvline(0, color='red', linestyle='--', label='Zero Error')\n",
        "plt.xlabel('Prediction Error (y_pred_min_bid - y_test_min_bid)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Error Distribution for Min Bid Model')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc1d12ab",
      "metadata": {},
      "source": [
        "#### model_median_bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "8bb27848",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions\n",
        "y_pred_median_bid = model_median_bid.predict(X_test)\n",
        "\n",
        "# Compute MSLE\n",
        "msle_value_median_bid = mean_squared_log_error(y_test_median_bid, y_pred_median_bid)\n",
        "print(\"Median Bid Model MSLE:\", msle_value_median_bid)\n",
        "\n",
        "# Compute MSLE\n",
        "mae_value_median_bid = mean_absolute_error(y_test_median_bid, y_pred_median_bid)\n",
        "print(\"Median Bid Model MAE:\", mae_value_median_bid)\n",
        "\n",
        "# Compute R2 score\n",
        "r2_value_median_bid = r2_score(y_test_median_bid, y_pred_median_bid)\n",
        "print(\"Median Bid Model R2:\", r2_value_median_bid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "01b81da6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate errors\n",
        "errors_median_bid = y_pred_median_bid - y_test_median_bid\n",
        "\n",
        "# Compute mean and standard deviation of errors\n",
        "mean_error_median_bid = np.mean(errors_median_bid)\n",
        "std_error_median_bid = np.std(errors_median_bid)\n",
        "\n",
        "# Compute 2.5th and 97.5th percentiles for the error distribution\n",
        "percentile_2_5_median_bid = np.percentile(errors_median_bid, 2.5)\n",
        "percentile_97_5_median_bid = np.percentile(errors_median_bid, 97.5)\n",
        "\n",
        "# Print values\n",
        "print(f\"2.5th percentile: {percentile_2_5_median_bid:.2f}\")\n",
        "print(f\"97.5th percentile: {percentile_97_5_median_bid:.2f}\")\n",
        "print(f\"Mean error: {mean_error_median_bid:.2f}\")\n",
        "print(f\"Std error: {std_error_median_bid:.2f}\")\n",
        "\n",
        "# Generate values for normal distribution curve\n",
        "x_values_median_bid = np.linspace(min(errors_median_bid), max(errors_median_bid), 100)\n",
        "y_values_median_bid = stats.norm.pdf(x_values_median_bid, mean_error_median_bid, std_error_median_bid) * len(errors_median_bid) * (max(errors_median_bid) - min(errors_median_bid)) / 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "22ae8d71",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot histogram of errors\n",
        "plt.hist(errors_median_bid, bins=50, alpha=0.7, color='blue', density=False, label=\"Error Distribution\")\n",
        "\n",
        "# Plot normal distribution curve\n",
        "plt.plot(x_values_median_bid, y_values_median_bid, color='black', linestyle='-', linewidth=2, label=\"Normal Approximation\")\n",
        "\n",
        "# Add vertical lines for standard deviations\n",
        "for i in range(1, 4):\n",
        "    plt.axvline(mean_error_median_bid + i * std_error_median_bid, color='green', linestyle='--', label=f'+{i} SD' if i == 1 else None)\n",
        "    plt.axvline(mean_error_median_bid - i * std_error_median_bid, color='green', linestyle='--', label=f'-{i} SD' if i == 1 else None)\n",
        "\n",
        "# Add vertical lines for percentiles\n",
        "plt.axvline(percentile_2_5_median_bid, color='orange', linestyle='--', label='2.5th Percentile')\n",
        "plt.axvline(percentile_97_5_median_bid, color='orange', linestyle='--', label='97.5th Percentile')\n",
        "\n",
        "# Labels and title\n",
        "plt.axvline(0, color='red', linestyle='--', label='Zero Error')\n",
        "plt.xlabel('Prediction Error (y_pred_median_bid - y_test_median_bid)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Error Distribution for Median Bid Model')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45804514",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "## **3. Safety Factors and Analysis** \n",
        "Experiment with safety factors to improve TP rate. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d88f6e",
      "metadata": {},
      "source": [
        "#### model_min_bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "10778c2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize lists to store results\n",
        "safety_factors = np.arange(-0.50, 2.01, 0.01)\n",
        "tpr_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Loop through safety factors\n",
        "for sf in safety_factors:\n",
        "    # Apply safety factor to predictions\n",
        "    adjusted_pred = y_pred_min_bid * (1 + sf)\n",
        "\n",
        "    # Compute TP Rate\n",
        "    pred_binary = (adjusted_pred >= y_test_min_bid).astype(int)\n",
        "    tp_rate = pred_binary.mean()\n",
        "\n",
        "    # Compute Mean Loss (average difference between predicted and actual)\n",
        "    mean_loss = np.mean(adjusted_pred - y_test_min_bid)\n",
        "\n",
        "    # Store TPR and Loss\n",
        "    tpr_values.append(tp_rate)\n",
        "    loss_values.append(mean_loss)\n",
        "\n",
        "# Print MSLE and initial TPR (without safety factor)\n",
        "print(\"Min Bid Model MSLE:\", msle_value_min_bid)\n",
        "print(\"Min Bid Model Initial TPR (no safety factor):\", tpr_values[0])\n",
        "\n",
        "# Plot TPR and Mean Loss with Dual Y-Axes\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Plot TPR on the left y-axis\n",
        "ax1.plot(safety_factors, tpr_values, marker='o', color='blue', label='True Positive Rate (TPR)')\n",
        "ax1.set_xlabel('Safety Factor')\n",
        "ax1.set_ylabel('True Positive Rate (TPR)', color='blue')\n",
        "ax1.tick_params(axis='y', labelcolor='blue')\n",
        "ax1.set_title('Effect of Safety Factor on TPR and Mean Loss - Min Bid Model')\n",
        "ax1.grid(True)\n",
        "\n",
        "# Plot Mean Loss on the right y-axis\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(safety_factors, loss_values, marker='x', color='orange', label='Mean Loss (Predicted - Actual)')\n",
        "ax2.set_ylabel('Mean Loss (Predicted - Actual)', color='orange')\n",
        "ax2.tick_params(axis='y', labelcolor='orange')\n",
        "\n",
        "# Add a legend for clarity\n",
        "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ee44faec",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert safety factor list to a NumPy array for easier indexing\n",
        "safety_factors = np.arange(-0.50, 2.01, 0.01)\n",
        "\n",
        "# Find the best safety factor based on maximizing TPR while minimizing loss\n",
        "# Define an optimality criterion: maximize TPR while keeping loss close to zero or minimal\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "tpr_values = np.array(tpr_values)\n",
        "loss_values = np.array(loss_values)\n",
        "\n",
        "# Define a balance factor (weights between TPR and loss minimization)\n",
        "alpha = 0.7  # Weight for TPR importance (can be tuned)\n",
        "beta = 0.3   # Weight for minimizing loss\n",
        "\n",
        "# Normalize values for fair comparison\n",
        "tpr_normalized = (tpr_values - np.min(tpr_values)) / (np.max(tpr_values) - np.min(tpr_values))\n",
        "loss_normalized = (loss_values - np.min(loss_values)) / (np.max(loss_values) - np.min(loss_values))\n",
        "\n",
        "# Compute a combined score (higher is better)\n",
        "optimality_score = alpha * tpr_normalized - beta * np.abs(loss_normalized)\n",
        "\n",
        "# Find the index of the best safety factor\n",
        "best_index = np.argmax(optimality_score)\n",
        "best_safety_factor = safety_factors[best_index]\n",
        "best_tpr = tpr_values[best_index]\n",
        "best_loss = loss_values[best_index]\n",
        "\n",
        "# Print the best safety factor details\n",
        "print(f\"Best Safety Factor: {best_safety_factor:.2f}\")\n",
        "print(f\"Corresponding TPR: {best_tpr:.2f}\")\n",
        "print(f\"Corresponding Mean Loss: {best_loss:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fd68490",
      "metadata": {},
      "source": [
        "#### model_median_bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ee9be271",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize lists to store results\n",
        "safety_factors = np.arange(-0.50, 2.01, 0.01)\n",
        "tpr_values = []\n",
        "loss_values = []\n",
        "\n",
        "# Loop through safety factors\n",
        "for sf in safety_factors:\n",
        "    # Apply safety factor to predictions\n",
        "    adjusted_pred = y_pred_median_bid * (1 + sf)\n",
        "\n",
        "    # Compute TP Rate\n",
        "    pred_binary = (adjusted_pred >= y_test_median_bid).astype(int)\n",
        "    tp_rate = pred_binary.mean()\n",
        "\n",
        "    # Compute Mean Loss (average difference between predicted and actual)\n",
        "    mean_loss = np.mean(adjusted_pred - y_test_median_bid)\n",
        "\n",
        "    # Store TPR and Loss\n",
        "    tpr_values.append(tp_rate)\n",
        "    loss_values.append(mean_loss)\n",
        "\n",
        "# Print MSLE and initial TPR (without safety factor)\n",
        "print(\"Median Bid Model MSLE:\", msle_value_median_bid)\n",
        "print(\"Median Bid Model Initial TPR (no safety factor):\", tpr_values[0])\n",
        "\n",
        "# Plot TPR and Mean Loss with Dual Y-Axes\n",
        "fig, ax1 = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Plot TPR on the left y-axis\n",
        "ax1.plot(safety_factors, tpr_values, marker='o', color='blue', label='True Positive Rate (TPR)')\n",
        "ax1.set_xlabel('Safety Factor')\n",
        "ax1.set_ylabel('True Positive Rate (TPR)', color='blue')\n",
        "ax1.tick_params(axis='y', labelcolor='blue')\n",
        "ax1.set_title('Effect of Safety Factor on TPR and Mean Loss - Median Bid Model')\n",
        "ax1.grid(True)\n",
        "\n",
        "# Plot Mean Loss on the right y-axis\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(safety_factors, loss_values, marker='x', color='orange', label='Mean Loss (Predicted - Actual)')\n",
        "ax2.set_ylabel('Mean Loss (Predicted - Actual)', color='orange')\n",
        "ax2.tick_params(axis='y', labelcolor='orange')\n",
        "\n",
        "# Add a legend for clarity\n",
        "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ceedb121",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert safety factor list to a NumPy array for easier indexing\n",
        "safety_factors = np.arange(-0.50, 2.01, 0.01)\n",
        "\n",
        "# Find the best safety factor based on maximizing TPR while minimizing loss\n",
        "# Define an optimality criterion: maximize TPR while keeping loss close to zero or minimal\n",
        "\n",
        "# Convert lists to NumPy arrays\n",
        "tpr_values = np.array(tpr_values)\n",
        "loss_values = np.array(loss_values)\n",
        "\n",
        "# Define a balance factor (weights between TPR and loss minimization)\n",
        "alpha = 0.7  # Weight for TPR importance (can be tuned)\n",
        "beta = 0.3   # Weight for minimizing loss\n",
        "\n",
        "# Normalize values for fair comparison\n",
        "tpr_normalized = (tpr_values - np.min(tpr_values)) / (np.max(tpr_values) - np.min(tpr_values))\n",
        "loss_normalized = (loss_values - np.min(loss_values)) / (np.max(loss_values) - np.min(loss_values))\n",
        "\n",
        "# Compute a combined score (higher is better)\n",
        "optimality_score = alpha * tpr_normalized - beta * np.abs(loss_normalized)\n",
        "\n",
        "# Find the index of the best safety factor\n",
        "best_index = np.argmax(optimality_score)\n",
        "best_safety_factor = safety_factors[best_index]\n",
        "best_tpr = tpr_values[best_index]\n",
        "best_loss = loss_values[best_index]\n",
        "\n",
        "# Print the best safety factor details\n",
        "print(f\"Best Safety Factor: {best_safety_factor:.2f}\")\n",
        "print(f\"Corresponding TPR: {best_tpr:.2f}\")\n",
        "print(f\"Corresponding Mean Loss: {best_loss:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6148a3fe",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "## **4. Feature Importance** \n",
        "Top features contributing to prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ae0d427",
      "metadata": {},
      "source": [
        "#### model_min_bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6e9d1ad7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use model's internal feature names\n",
        "features = model_min_bid.feature_names_\n",
        "\n",
        "# Get feature importance scores\n",
        "feature_importance = model_min_bid.get_feature_importance(type='FeatureImportance')\n",
        "\n",
        "# Create a DataFrame for better readability\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display top features\n",
        "top_features = importance_df\n",
        "print(top_features)\n",
        "\n",
        "# Visualize feature importance\n",
        "top_features.plot(kind='bar', x='Feature', y='Importance', legend=False, title=\"Top Feature Importance\")\n",
        "plt.ylabel(\"Importance Score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24265a3",
      "metadata": {},
      "source": [
        "#### model_median_bid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "c89c0b67",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use model's internal feature names\n",
        "features = model_median_bid.feature_names_\n",
        "\n",
        "# Get feature importance scores\n",
        "feature_importance = model_median_bid.get_feature_importance(type='FeatureImportance')\n",
        "\n",
        "# Create a DataFrame for better readability\n",
        "importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importance})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display top features\n",
        "top_features = importance_df\n",
        "print(top_features)\n",
        "\n",
        "# Visualize feature importance\n",
        "top_features.plot(kind='bar', x='Feature', y='Importance', legend=False, title=\"Top Feature Importance\")\n",
        "plt.ylabel(\"Importance Score\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "499428bb",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "## **5. Sample prediction**\n",
        "Test the models using a given example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "67e9872a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the new data instance\n",
        "new_data = pd.DataFrame({\n",
        "    'Term': [2],\n",
        "    'Description': [\"Enterprise Solution Management\"],\n",
        "    'Section': [\"G1\"],\n",
        "    'Vacancy': [40],\n",
        "    'Before Process Vacancy': [38],\n",
        "    'Instructor': [\"RAFAEL J. BARROS\"],\n",
        "    'Grading Basis': [\"Graded\"],\n",
        "    'class1_day': [\"Mon\"],\n",
        "    'class1_starttime': [\"08:15\"],\n",
        "    'class1_venue': [\"SOE/SCIS2 Seminar Room B1-2\"],\n",
        "    'class2_day': [\"NA\"],\n",
        "    'class2_starttime': [\"NA\"],\n",
        "    'class2_venue': [\"NA\"],\n",
        "    'class3_day': [\"NA\"],\n",
        "    'class3_starttime': [\"NA\"],\n",
        "    'class3_venue': [\"NA\"],\n",
        "    'exam_startdate': [\"21-Apr-2025\"], \n",
        "    'exam_day': [\"Mon\"],\n",
        "    'exam_starttime': [\"13:00\"],\n",
        "    'AY': [2024],\n",
        "    'Incoming Freshman': [\"no\"],\n",
        "    'Incoming Exchange': [\"no\"],\n",
        "    'Round': [\"1\"],\n",
        "    'Window': [1],\n",
        "    'SubjectArea': [\"IS\"],\n",
        "    'CatalogueNo': [\"214\"],\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "cb7dd0a3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply preprocessing\n",
        "new_data_preprocessed = standardise_data_types(new_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "27b7a557",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict Min Bid Price\n",
        "predicted_min_bid = model_min_bid.predict(new_data_preprocessed)[0]\n",
        "\n",
        "# Predict Median Bid Price\n",
        "predicted_median_bid = model_median_bid.predict(new_data_preprocessed)[0]\n",
        "\n",
        "# Print Results\n",
        "print(f\"Predicted Min Bid: {predicted_min_bid:.2f}\")\n",
        "print(f\"Predicted Median Bid: {predicted_median_bid:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "077fa7a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the trained model to a file\n",
        "model_min_bid.save_model(\"catboost_min_bid.cbm\", format=\"cbm\")\n",
        "\n",
        "# Save the second model (for median bid)\n",
        "model_median_bid.save_model(\"catboost_median_bid.cbm\", format=\"cbm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e7bae5b",
      "metadata": {},
      "source": [
        "\n",
        "---\n",
        "## **6. Conclusion**\n",
        "\n",
        "### **What has improved?**\n",
        "1. **Fixed bugs**\n",
        "   - Removed features that are future dependent.\n",
        "   - Standardised categorical variable input.\n",
        "   - Optimise outlier fixing.\n",
        "2. **Easy use and implementation**\n",
        "   - After much consideration, I have released the cbm model such that no re-training of the model is required.\n",
        "   - You can use the model here **[example_prediction.ipynb](example_prediction.ipynb)**\n",
        "\n",
        "### **What to Do Next**\n",
        "1. **Data Collection**:\n",
        "   - Collaborate with students to crowdsource individual bid data for richer insights.\n",
        "2. **Deployment to website**\n",
        "   - Currently in collaboration with afterclass to implement this as part of the bid analytics.\n",
        "   - Allowing students to use the model while generating additional insights, adhering to privacy policies.\n",
        "\n",
        "Thank you for experimenting with me! Hope to develop better models that are more capable of predicting min bid prices!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "BidlyEnv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
