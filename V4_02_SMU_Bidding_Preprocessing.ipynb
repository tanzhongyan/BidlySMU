{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "101bbc8b",
   "metadata": {},
   "source": [
    "# **SMU Course Bidding Data Preprocessing**\n",
    "\n",
    "<div style=\"background-color:#DFFFD6; padding:12px; border-radius:5px; border: 1px solid #228B22;\">\n",
    "    \n",
    "  <h2 style=\"color:#006400;\">âœ… Looking to Implement This? âœ…</h2>\n",
    "  \n",
    "  <p>ðŸš€ Get started quickly by using <strong><a href=\"example_prediction.ipynb\">example_prediction.ipynb</a></strong>.</p>\n",
    "  \n",
    "  <ul>\n",
    "    <li>ðŸ“Œ **Pre-trained CatBoost model (`.cbm`) available for instant predictions.**</li>\n",
    "    <li>ðŸ”§ Includes **step-by-step instructions** for making predictions.</li>\n",
    "    <li>âš¡ Works **out-of-the-box**â€”just load the model and start predicting!</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3>ðŸ”— ðŸ“Œ Next Steps:</h3>\n",
    "  <p>ðŸ‘‰ <a href=\"example_prediction.ipynb\"><strong>Go to Example Prediction Notebook</strong></a></p>\n",
    "\n",
    "</div>\n",
    "\n",
    "### **Changes in V4**\n",
    "- Replaced `BidderCount` with `Before Process Vacancy` due to future dependent results like `After Process Vacancy` which is not available at prediction time.\n",
    "- Development of two models, one for `Median Bid Price` and `Min Bid Price`.\n",
    "- Refined model input to make ingesting data for prediction easier. No label encoding done for `Term` or `Round`.\n",
    "\n",
    "### **Objective**\n",
    "This notebook performs the following steps:\n",
    "1. **Data Cleaning** - Handle redundant columns and remove unwanted data.\n",
    "2. **Feature Engineering** - Create derived features.\n",
    "3. **Exploratory Data Analysis (EDA)** - Analyze key features and outlier cleaning.\n",
    "4. **Save Processed Data** - Save the data into a csv that is useable for other ML models\n",
    "\n",
    "### **Requirements**\n",
    "- Python 3.x\n",
    "- TensorFlow, Pandas, NumPy, Matplotlib, Seaborn, Sklearn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764b043",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## **1. Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ba9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c43e1",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## **2. SMUBiddingTransformer Class**\n",
    "\n",
    "### **SMU Bidding Data Feature Engineering Transformer**\n",
    "\n",
    "#### **What This Code Does**\n",
    "The `SMUBiddingTransformer` class is a comprehensive feature engineering pipeline designed specifically for Singapore Management University (SMU) course bidding data and optimized for CatBoost model training. It transforms raw tabular bidding data into machine learning-ready features while preserving categorical features where beneficial for CatBoost and creating embeddings only for high-cardinality features.\n",
    "\n",
    "**Key Features:**\n",
    "- **CatBoost-Optimized**: Preserves categorical features in their natural form for CatBoost's superior categorical handling while creating embeddings only for high-cardinality features (instructors, day combinations)\n",
    "- **Feature Type Tracking**: Automatically categorizes features into categorical, numeric, and embedding types with dedicated getter methods for each\n",
    "- **Smart Missing Value Handling**: Configurable approach to missing values - either let CatBoost handle them natively or create embeddings for missing data\n",
    "- **High-Cardinality Embeddings**: Creates dense vector representations of instructor names (1000+ unique) and day-of-week combinations using TF-IDF + SVD\n",
    "- **Course Code Intelligence**: Parses various course code formats including hyphenated codes ('COR-COMM175') and standard formats ('MGMT715')\n",
    "- **Bidding Window Parsing**: Extracts round numbers (including 1A, 1B, 2A formats) and window numbers from complex bidding window strings\n",
    "- **Categorical Preservation**: Keeps start_time, term, course_name, subject_area as categorical for CatBoost's target encoding\n",
    "- **Sklearn-Compatible**: Standard transformer interface with `fit()`, `transform()`, and `fit_transform()` methods\n",
    "\n",
    "#### **What Is Required**\n",
    "\n",
    "**Input Data Format:**\n",
    "The transformer expects a pandas DataFrame with these **required columns**:\n",
    "- `course_code` (str): Course identifier (e.g., 'MGMT715', 'COR-COMM175')\n",
    "- `course_name` (str): Full course name\n",
    "- `acad_year_start` (int): Academic year start (e.g., 2025)\n",
    "- `term` (str): Academic term ('1', '2', '3A', '3B')\n",
    "- `start_time` (str): Class start time (e.g., '19:30', 'TBA') - preserved as categorical\n",
    "- `day_of_week` (str): Days of week, can be comma-separated (e.g., 'Mon,Thu')\n",
    "- `before_process_vacancy` (int): Number of available vacancies\n",
    "- `bidding_window` (str): Bidding window descriptor (e.g., 'Round 1 Window 1', 'Incoming Freshmen Rnd 1 Win 4')\n",
    "- `instructor` (str): Instructor names, can be comma-separated (e.g., 'JOHN DOE, JANE SMITH')\n",
    "\n",
    "**Technical Dependencies:**\n",
    "- Python packages: `pandas`, `numpy`, `sklearn` (TfidfVectorizer, TruncatedSVD)\n",
    "- Standard libraries: `typing`, `warnings`, `re`\n",
    "\n",
    "**Configuration Parameters:**\n",
    "- `n_instructor_components` (int, default=50): Embedding dimensions for instructor names (expected 1000+ unique instructors)\n",
    "- `n_day_components` (int, default=20): Embedding dimensions for day-of-week combinations (handles 7! combinations)\n",
    "- `use_embeddings_for_missing` (bool, default=False): If True, missing values get embeddings. If False (recommended), missing values remain as None/NaN for CatBoost to handle natively\n",
    "\n",
    "#### **Output Format**\n",
    "The transformer produces a pandas DataFrame with engineered features organized into three categories:\n",
    "\n",
    "**Categorical Features** (for CatBoost's `cat_features` parameter):\n",
    "- `subject_area`, `catalogue_no`, `round`, `term`, `start_time`, `course_name`\n",
    "\n",
    "**Numeric Features:**\n",
    "- `window`, `before_process_vacancy`, `acad_year_start`\n",
    "\n",
    "**Embedding Features:**\n",
    "- `instructor_embed_0` through `instructor_embed_{n_instructor_components-1}` (50 by default)\n",
    "- `day_embed_0` through `day_embed_{n_day_components-1}` (20 by default)\n",
    "\n",
    "#### **Usage in Jupyter Notebook**\n",
    "\n",
    "**Basic Usage:**\n",
    "```python\n",
    "from your_module import SMUBiddingTransformer\n",
    "\n",
    "# Initialize transformer\n",
    "transformer = SMUBiddingTransformer(\n",
    "    n_instructor_components=50,     # Instructor embedding size\n",
    "    n_day_components=20,            # Day-of-week embedding size  \n",
    "    use_embeddings_for_missing=False # Let CatBoost handle missing values\n",
    ")\n",
    "\n",
    "# Fit on training data and transform\n",
    "X_train = transformer.fit_transform(training_dataframe)\n",
    "\n",
    "# Transform new data (after fitting)\n",
    "X_test = transformer.transform(test_dataframe)\n",
    "\n",
    "# Get feature lists for CatBoost\n",
    "categorical_features = transformer.get_categorical_features()\n",
    "numeric_features = transformer.get_numeric_features()\n",
    "embedding_features = transformer.get_embedding_features()\n",
    "```\n",
    "\n",
    "**CatBoost Integration:**\n",
    "```python\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Initialize transformer and prepare data\n",
    "transformer = SMUBiddingTransformer(use_embeddings_for_missing=False)\n",
    "X_train = transformer.fit_transform(training_dataframe)\n",
    "X_test = transformer.transform(test_dataframe)\n",
    "\n",
    "# Use transformer's feature categorization\n",
    "model = CatBoostRegressor(\n",
    "    cat_features=transformer.get_categorical_features(),\n",
    "    iterations=1000,\n",
    "    learning_rate=0.03,\n",
    "    depth=6,\n",
    "    one_hot_max_size=10  # CatBoost will use target encoding for larger categories\n",
    ")\n",
    "\n",
    "# Fit and predict\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "```\n",
    "\n",
    "**Feature Inspection:**\n",
    "```python\n",
    "# Check what features were generated\n",
    "print(\"Transformed shape:\", X_train.shape)\n",
    "print(\"\\nCategorical features for CatBoost:\")\n",
    "print(transformer.get_categorical_features())\n",
    "print(f\"\\nNumeric features ({len(transformer.get_numeric_features())}):\")\n",
    "print(transformer.get_numeric_features())\n",
    "print(f\"\\nEmbedding features ({len(transformer.get_embedding_features())}):\")\n",
    "print(transformer.get_embedding_features()[:10])  # First 10\n",
    "```\n",
    "\n",
    "**Resume Capability:**\n",
    "- **Stateful Transformer**: Once fitted, maintains vectorizers and SVD components for consistent transformations\n",
    "- **Missing Value Strategy**: Configurable handling - either create embeddings for missing data or let CatBoost handle them natively (recommended)\n",
    "- **Feature Consistency**: Maintains consistent categorical/numeric/embedding separation across different datasets\n",
    "- **Validation**: Validates input columns and provides clear error messages for missing required fields\n",
    "\n",
    "**Notes:**\n",
    "- Optimized specifically for CatBoost's categorical feature handling capabilities\n",
    "- High-cardinality features (instructors, day combinations) get embeddings while low-cardinality features remain categorical\n",
    "- The `use_embeddings_for_missing=False` default lets CatBoost handle missing values with its built-in missing value support\n",
    "- Feature type tracking enables easy CatBoost configuration without manual feature specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e2ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class SMUBiddingTransformer:\n",
    "    \"\"\"\n",
    "    A reusable transformer class for processing SMU course bidding data\n",
    "    optimized for CatBoost model.\n",
    "    \n",
    "    This transformer preserves categorical features where beneficial for CatBoost\n",
    "    while creating embeddings for high-cardinality features (instructors, day combinations).\n",
    "    \n",
    "    Expected input columns:\n",
    "    - course_code: str (e.g. 'MGMT715', 'COR-COMM175')\n",
    "    - course_name: str\n",
    "    - acad_year_start: int\n",
    "    - term: str ('1', '2', '3A', '3B')\n",
    "    - start_time: str (e.g. '19:30', 'TBA') - preserved as categorical\n",
    "    - day_of_week: str (can be multivalued, e.g. 'Mon,Thu')\n",
    "    - before_process_vacancy: int\n",
    "    - bidding_window: str (e.g. 'Round 1 Window 1', 'Incoming Freshmen Rnd 1 Win 4')\n",
    "    - instructor: str (can be multivalued, e.g. 'JOHN DOE, JANE SMITH')\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_instructor_components: int = 50, \n",
    "                 n_day_components: int = 20,\n",
    "                 use_embeddings_for_missing: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the transformer with embedding dimensions.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_instructor_components : int, default=50\n",
    "            Number of dimensions for instructor embeddings (expected 1000+ unique instructors)\n",
    "        n_day_components : int, default=20\n",
    "            Number of dimensions for day_of_week embeddings (handles 7! combinations)\n",
    "        use_embeddings_for_missing : bool, default=False\n",
    "            If True, missing values get embeddings. If False, they remain as None/NaN\n",
    "            for CatBoost to handle natively\n",
    "        \"\"\"\n",
    "        self.n_instructor_components = n_instructor_components\n",
    "        self.n_day_components = n_day_components\n",
    "        self.use_embeddings_for_missing = use_embeddings_for_missing\n",
    "        \n",
    "        # Vectorizers for high-cardinality features only\n",
    "        self.instructor_vectorizer = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            token_pattern=r'\\b\\w+\\b',\n",
    "            ngram_range=(1, 2)  # Capture name variations\n",
    "        )\n",
    "        self.instructor_svd = TruncatedSVD(\n",
    "            n_components=n_instructor_components, \n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Day combination vectorizer\n",
    "        self.day_vectorizer = TfidfVectorizer(\n",
    "            max_features=150,\n",
    "            token_pattern=r'\\b\\w+\\b'\n",
    "        )\n",
    "        self.day_svd = TruncatedSVD(\n",
    "            n_components=n_day_components,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        # Fitted flags\n",
    "        self.is_fitted = False\n",
    "        \n",
    "        # Lists to track categorical features for CatBoost\n",
    "        self.categorical_features = []\n",
    "        self.numeric_features = []\n",
    "        self.embedding_features = []\n",
    "        \n",
    "    def fit(self, df: pd.DataFrame) -> 'SMUBiddingTransformer':\n",
    "        \"\"\"\n",
    "        Fit the transformer on training data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : pandas.DataFrame\n",
    "            Training dataframe with all required columns\n",
    "        \"\"\"\n",
    "        # Validate required columns\n",
    "        required_cols = [\n",
    "            'course_code', 'course_name', 'acad_year_start', 'term',\n",
    "            'start_time', 'day_of_week', 'before_process_vacancy',\n",
    "            'bidding_window', 'instructor'\n",
    "        ]\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Process instructors for embeddings (high cardinality)\n",
    "        instructor_texts = self._process_instructor_for_embedding(df['instructor'])\n",
    "        if self.use_embeddings_for_missing or any(text != '' for text in instructor_texts):\n",
    "            instructor_tfidf = self.instructor_vectorizer.fit_transform(instructor_texts)\n",
    "            self.instructor_svd.fit(instructor_tfidf)\n",
    "        \n",
    "        # Process day combinations for embeddings (high cardinality)\n",
    "        day_texts = self._process_day_for_embedding(df['day_of_week'])\n",
    "        if self.use_embeddings_for_missing or any(text != '' for text in day_texts):\n",
    "            day_tfidf = self.day_vectorizer.fit_transform(day_texts)\n",
    "            self.day_svd.fit(day_tfidf)\n",
    "        \n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Transform the dataframe to CatBoost-ready format.\n",
    "        \n",
    "        Returns both the transformed dataframe and lists of categorical feature indices\n",
    "        for CatBoost's cat_features parameter.\n",
    "        \"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Transformer must be fitted before transform. Call fit() first.\")\n",
    "        \n",
    "        # Create a copy to avoid modifying original\n",
    "        df_transformed = df.copy()\n",
    "        \n",
    "        # Reset feature tracking\n",
    "        self.categorical_features = []\n",
    "        self.numeric_features = []\n",
    "        self.embedding_features = []\n",
    "        all_features = []\n",
    "        \n",
    "        # 1. Extract course components (categorical + numeric)\n",
    "        course_features = self._extract_course_features(df_transformed)\n",
    "        all_features.append(course_features)\n",
    "        \n",
    "        # 2. Process bidding window (categorical + numeric)\n",
    "        round_window_features = self._extract_round_window(df_transformed)\n",
    "        all_features.append(round_window_features)\n",
    "        \n",
    "        # 3. Basic features (preserve categorical nature)\n",
    "        basic_features = self._process_basic_features(df_transformed)\n",
    "        all_features.append(basic_features)\n",
    "        \n",
    "        # 4. Create instructor embeddings (only for non-missing)\n",
    "        instructor_embeddings = self._create_instructor_embeddings(df_transformed)\n",
    "        if instructor_embeddings is not None:\n",
    "            all_features.append(instructor_embeddings)\n",
    "        \n",
    "        # 5. Create day embeddings (only for non-missing)\n",
    "        day_embeddings = self._create_day_embeddings(df_transformed)\n",
    "        if day_embeddings is not None:\n",
    "            all_features.append(day_embeddings)\n",
    "        \n",
    "        # Combine all features\n",
    "        final_df = pd.concat(all_features, axis=1)\n",
    "        \n",
    "        return final_df\n",
    "    \n",
    "    def fit_transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Fit the transformer and transform the data in one step.\"\"\"\n",
    "        self.fit(df)\n",
    "        return self.transform(df)\n",
    "    \n",
    "    def get_categorical_features(self) -> List[str]:\n",
    "        \"\"\"Get list of categorical feature names for CatBoost.\"\"\"\n",
    "        return self.categorical_features.copy()\n",
    "    \n",
    "    def get_numeric_features(self) -> List[str]:\n",
    "        \"\"\"Get list of numeric feature names.\"\"\"\n",
    "        return self.numeric_features.copy()\n",
    "    \n",
    "    def get_embedding_features(self) -> List[str]:\n",
    "        \"\"\"Get list of embedding feature names.\"\"\"\n",
    "        return self.embedding_features.copy()\n",
    "    \n",
    "    def _extract_course_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Extract subject area and catalogue number from course code.\"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "        \n",
    "        def split_course_code(code):\n",
    "            \"\"\"Split course code into subject area and catalogue number.\"\"\"\n",
    "            if pd.isna(code):\n",
    "                return None, None\n",
    "            \n",
    "            code = str(code).strip().upper()\n",
    "            \n",
    "            # Handle hyphenated codes like 'COR-COMM175'\n",
    "            if '-' in code:\n",
    "                parts = code.split('-')\n",
    "                if len(parts) >= 2:\n",
    "                    subject = '-'.join(parts[:-1])\n",
    "                    # Extract number from last part\n",
    "                    num_match = re.search(r'(\\d+)', parts[-1])\n",
    "                    if num_match:\n",
    "                        return subject, int(num_match.group(1))\n",
    "                    else:\n",
    "                        # Try extracting from full last part\n",
    "                        num_match = re.search(r'(\\d+)', code)\n",
    "                        if num_match:\n",
    "                            return subject, int(num_match.group(1))\n",
    "            \n",
    "            # Standard format like 'MGMT715'\n",
    "            match = re.match(r'([A-Z\\-]+)(\\d+)', code)\n",
    "            if match:\n",
    "                return match.group(1), int(match.group(2))\n",
    "            \n",
    "            return code, 0\n",
    "        \n",
    "        # Extract components\n",
    "        splits = df['course_code'].apply(split_course_code)\n",
    "        features['subject_area'] = splits.apply(lambda x: x[0] if x else None)\n",
    "        features['catalogue_no'] = splits.apply(lambda x: x[1] if x else 0)\n",
    "        \n",
    "        # subject_area and catalogue_no are categorical for CatBoost\n",
    "        self.categorical_features.extend(['subject_area', 'catalogue_no'])\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _extract_round_window(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Extract round and window from bidding_window string.\"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "        \n",
    "        def parse_bidding_window(window_str):\n",
    "            \"\"\"Parse bidding window string into round and window number.\"\"\"\n",
    "            if pd.isna(window_str):\n",
    "                return None, None\n",
    "            \n",
    "            window_str = str(window_str).strip()\n",
    "            \n",
    "            # Handle patterns from V4_01 notebook\n",
    "            import re\n",
    "            match = re.search(r'Round\\s+(\\d[A-C]?)\\s+Window\\s+(\\d)', window_str, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1), int(match.group(2))\n",
    "            \n",
    "            match = re.search(r'Rnd\\s+(\\d[A-C]?)\\s+Win\\s+(\\d)', window_str, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1), int(match.group(2))\n",
    "            \n",
    "            match = re.search(r'(\\d[A-C]?)', window_str)\n",
    "            if match:\n",
    "                win_match = re.search(r'Window\\s+(\\d)|Win\\s+(\\d)', window_str, re.IGNORECASE)\n",
    "                if win_match:\n",
    "                    window_num = int(win_match.group(1) or win_match.group(2))\n",
    "                    return match.group(1), window_num\n",
    "                return match.group(1), 1\n",
    "            \n",
    "            return '1', 1\n",
    "        \n",
    "        # Extract round and window\n",
    "        parsed = df['bidding_window'].apply(parse_bidding_window)\n",
    "        features['round'] = parsed.apply(lambda x: x[0] if x else '1')\n",
    "        features['window'] = parsed.apply(lambda x: x[1] if x else 1)\n",
    "        \n",
    "        # Round as categorical (preserves ordering like 1, 1A, 1B, 2, 2A)\n",
    "        self.categorical_features.append('round')\n",
    "        \n",
    "        # Window as numeric\n",
    "        self.numeric_features.append('window')\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _process_basic_features(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Process basic features, preserving categorical nature where beneficial.\"\"\"\n",
    "        features = pd.DataFrame(index=df.index)\n",
    "        \n",
    "        # Numeric features\n",
    "        features['before_process_vacancy'] = pd.to_numeric(\n",
    "            df['before_process_vacancy'], errors='coerce'\n",
    "        ).fillna(0)\n",
    "        features['acad_year_start'] = pd.to_numeric(\n",
    "            df['acad_year_start'], errors='coerce'\n",
    "        ).fillna(2025)\n",
    "        \n",
    "        self.numeric_features.extend(['before_process_vacancy', 'acad_year_start'])\n",
    "        \n",
    "        # Categorical features\n",
    "        features['term'] = df['term'].astype(str)\n",
    "        features['start_time'] = df['start_time'].astype(str)\n",
    "        features['course_name'] = df['course_name'].astype(str)\n",
    "        \n",
    "        # Replace empty strings with None for proper CatBoost handling\n",
    "        features.loc[features['start_time'].isin(['', 'nan']), 'start_time'] = None\n",
    "        features.loc[features['course_name'].isin(['', 'nan']), 'course_name'] = None\n",
    "        \n",
    "        self.categorical_features.extend(['term', 'start_time', 'course_name'])\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _process_instructor_for_embedding(self, instructor_series: pd.Series) -> List[str]:\n",
    "        \"\"\"Process instructor names for embedding - only non-missing values.\"\"\"\n",
    "        processed = []\n",
    "        \n",
    "        for instructor in instructor_series:\n",
    "            if pd.isna(instructor) or str(instructor).strip() == '' or str(instructor).upper() == 'TBA':\n",
    "                if self.use_embeddings_for_missing:\n",
    "                    processed.append('MISSING_INSTRUCTOR')\n",
    "                else:\n",
    "                    processed.append('')  # Will result in zero embeddings\n",
    "            else:\n",
    "                # Combine multiple instructors\n",
    "                names = [name.strip().upper() for name in str(instructor).split(',')]\n",
    "                processed.append(' '.join(names))\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    def _process_day_for_embedding(self, day_series: pd.Series) -> List[str]:\n",
    "        \"\"\"Process day combinations for embedding - only non-missing values.\"\"\"\n",
    "        processed = []\n",
    "        \n",
    "        day_abbrev = {\n",
    "            'MONDAY': 'MON', 'TUESDAY': 'TUE', 'WEDNESDAY': 'WED',\n",
    "            'THURSDAY': 'THU', 'FRIDAY': 'FRI', 'SATURDAY': 'SAT', 'SUNDAY': 'SUN',\n",
    "            'MON': 'MON', 'TUE': 'TUE', 'WED': 'WED', 'THU': 'THU',\n",
    "            'FRI': 'FRI', 'SAT': 'SAT', 'SUN': 'SUN'\n",
    "        }\n",
    "        \n",
    "        for days in day_series:\n",
    "            if pd.isna(days) or str(days).strip() == '':\n",
    "                if self.use_embeddings_for_missing:\n",
    "                    processed.append('MISSING_DAY')\n",
    "                else:\n",
    "                    processed.append('')  # Will result in zero embeddings\n",
    "            else:\n",
    "                # Handle multiple days\n",
    "                day_list = []\n",
    "                for day in str(days).split(','):\n",
    "                    day_upper = day.strip().upper()\n",
    "                    day_list.append(day_abbrev.get(day_upper, day_upper))\n",
    "                # Sort for consistency\n",
    "                day_list.sort()\n",
    "                processed.append('_'.join(day_list))\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    def _create_instructor_embeddings(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Create instructor embeddings only for non-missing values.\"\"\"\n",
    "        instructor_texts = self._process_instructor_for_embedding(df['instructor'])\n",
    "        \n",
    "        # Check if we have any non-empty texts\n",
    "        if not self.use_embeddings_for_missing and all(text == '' for text in instructor_texts):\n",
    "            return None\n",
    "        \n",
    "        # Transform using fitted vectorizer\n",
    "        instructor_tfidf = self.instructor_vectorizer.transform(instructor_texts)\n",
    "        instructor_embeddings = self.instructor_svd.transform(instructor_tfidf)\n",
    "        \n",
    "        # Create dataframe with embedding columns\n",
    "        embedding_cols = [f'instructor_embed_{i}' for i in range(self.n_instructor_components)]\n",
    "        instructor_df = pd.DataFrame(\n",
    "            instructor_embeddings,\n",
    "            columns=embedding_cols,\n",
    "            index=df.index\n",
    "        )\n",
    "        \n",
    "        # Set embeddings to 0 for missing instructors if not using embeddings for missing\n",
    "        if not self.use_embeddings_for_missing:\n",
    "            mask = [text == '' for text in instructor_texts]\n",
    "            instructor_df.loc[mask] = 0\n",
    "        \n",
    "        self.embedding_features.extend(embedding_cols)\n",
    "        \n",
    "        return instructor_df\n",
    "    \n",
    "    def _create_day_embeddings(self, df: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "        \"\"\"Create day combination embeddings only for non-missing values.\"\"\"\n",
    "        day_texts = self._process_day_for_embedding(df['day_of_week'])\n",
    "        \n",
    "        # Check if we have any non-empty texts\n",
    "        if not self.use_embeddings_for_missing and all(text == '' for text in day_texts):\n",
    "            return None\n",
    "        \n",
    "        # Transform using fitted vectorizer\n",
    "        day_tfidf = self.day_vectorizer.transform(day_texts)\n",
    "        day_embeddings = self.day_svd.transform(day_tfidf)\n",
    "        \n",
    "        # Create dataframe with embedding columns\n",
    "        embedding_cols = [f'day_embed_{i}' for i in range(self.n_day_components)]\n",
    "        day_df = pd.DataFrame(\n",
    "            day_embeddings,\n",
    "            columns=embedding_cols,\n",
    "            index=df.index\n",
    "        )\n",
    "        \n",
    "        # Set embeddings to 0 for missing days if not using embeddings for missing\n",
    "        if not self.use_embeddings_for_missing:\n",
    "            mask = [text == '' for text in day_texts]\n",
    "            day_df.loc[mask] = 0\n",
    "        \n",
    "        self.embedding_features.extend(embedding_cols)\n",
    "        \n",
    "        return day_df\n",
    "\n",
    "    \n",
    "    def get_feature_names(self) -> List[str]:\n",
    "        \"\"\"Get all feature names after transformation.\"\"\"\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Transformer must be fitted to get feature names.\")\n",
    "        \n",
    "        return self.categorical_features + self.numeric_features + self.embedding_features\n",
    "\n",
    "\n",
    "# Example usage with CatBoost\n",
    "if __name__ == \"__main__\":\n",
    "    # Create sample data\n",
    "    sample_data = pd.DataFrame({\n",
    "        'course_code': ['MGMT715', 'COR-COMM175', 'ECON101', 'STAT201'],\n",
    "        'course_name': ['Strategic Management', 'Business Communication', 'Principles of Economics', 'Applied Statistics'],\n",
    "        'acad_year_start': [2025, 2025, 2025, 2025],\n",
    "        'term': ['1', '2', '3A', '1'],\n",
    "        'start_time': ['19:30', '14:00', 'TBA', '10:00'],\n",
    "        'day_of_week': ['Mon,Thu', 'Tue', '', 'Mon,Wed,Fri'],\n",
    "        'before_process_vacancy': [10, 5, 15, 8],\n",
    "        'bidding_window': ['Round 1 Window 1', 'Round 2A Window 3', 'Incoming Freshmen Rnd 1 Win 2', 'Round 1B Window 2'],\n",
    "        'instructor': ['JOHN DOE, JANE SMITH', 'ROBERT LEE', 'TBA', '']\n",
    "    })\n",
    "    \n",
    "    # Initialize transformer\n",
    "    transformer = SMUBiddingTransformer(\n",
    "        n_instructor_components=30,\n",
    "        n_day_components=15,\n",
    "        use_embeddings_for_missing=False  # Let CatBoost handle missing values\n",
    "    )\n",
    "    \n",
    "    # Fit and transform\n",
    "    X_train = transformer.fit_transform(sample_data)\n",
    "    \n",
    "    print(\"Transformed shape:\", X_train.shape)\n",
    "    print(\"\\nCategorical features for CatBoost:\")\n",
    "    print(transformer.get_categorical_features())\n",
    "    print(\"\\nNumeric features:\")\n",
    "    print(transformer.get_numeric_features()[:10])  # First 10\n",
    "    print(\"\\nEmbedding features:\")\n",
    "    print(transformer.get_embedding_features()[:10])  # First 10\n",
    "    \n",
    "    # Example CatBoost integration\n",
    "    print(\"\\n# CatBoost Usage Example:\")\n",
    "    print(\"from catboost import CatBoostRegressor\")\n",
    "    print(\"model = CatBoostRegressor(\")\n",
    "    print(f\"    cat_features={transformer.get_categorical_features()},\")\n",
    "    print(\"    iterations=1000,\")\n",
    "    print(\"    learning_rate=0.03,\")\n",
    "    print(\"    depth=6\")\n",
    "    print(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4764a7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 files.\n",
      "Initial Data Shape: (121221, 29)\n",
      "             Term                   Session     Bidding Window Course Code  \\\n",
      "0  2021-22 Term 2  Regular Academic Session  Round 2A Window 3     ACCT001   \n",
      "1  2021-22 Term 2  Regular Academic Session  Round 2A Window 3     ACCT009   \n",
      "2  2021-22 Term 2  Regular Academic Session  Round 2A Window 3     ACCT101   \n",
      "3  2021-22 Term 2  Regular Academic Session  Round 2A Window 3     ACCT101   \n",
      "4  2021-22 Term 2  Regular Academic Session  Round 2A Window 3     ACCT101   \n",
      "\n",
      "                                                        Description Section  \\\n",
      "0                 Accounting Study Mission (Asian Studies)(Bangkok)      G1   \n",
      "1  Overseas Project Experience (Accounting in Asia)(SMU-X: Jakarta)      G1   \n",
      "2                                              Financial Accounting      G1   \n",
      "3                                              Financial Accounting     G10   \n",
      "4                                              Financial Accounting     G11   \n",
      "\n",
      "   Vacancy  Opening Vacancy  Before Process Vacancy  D.I.C.E  \\\n",
      "0       45               45                       1        0   \n",
      "1       25               24                       0        0   \n",
      "2       42               42                       0        0   \n",
      "3       45               45                       1        0   \n",
      "4       45               45                       0        0   \n",
      "\n",
      "   After Process Vacancy  Enrolled Students  Median Bid  Min Bid  \\\n",
      "0                      1                 44         0.0      0.0   \n",
      "1                      0                 24         0.0      0.0   \n",
      "2                      0                 42         0.0      0.0   \n",
      "3                      1                 44         0.0      0.0   \n",
      "4                      0                 45         0.0      0.0   \n",
      "\n",
      "                   Instructor School/Department Grading Basis class1_day  \\\n",
      "0     PRASART JONGJAROENKAMOL               SOA     Pass/Fail        Tue   \n",
      "1   YUANTO KUSNADI, KEVIN LEE               SOA     Pass/Fail        Mon   \n",
      "2                   GRACE FAN               SOA        Graded        Tue   \n",
      "3                TAN LAY KHIM               SOA        Graded        Thu   \n",
      "4                TAN LAY KHIM               SOA        Graded        Thu   \n",
      "\n",
      "  class1_starttime          class1_venue class2_day class2_starttime  \\\n",
      "0            15:30  SOA Seminar Room 2-2        NaN              NaN   \n",
      "1            12:00  SOA Seminar Room 2-4        NaN              NaN   \n",
      "2            08:15  SOA Seminar Room 2-4        NaN              NaN   \n",
      "3            08:15  SOA Seminar Room 3-4        NaN              NaN   \n",
      "4            12:00  SOA Seminar Room 3-4        NaN              NaN   \n",
      "\n",
      "  class2_venue class3_day class3_starttime class3_venue exam_startdate  \\\n",
      "0          NaN        NaN              NaN          NaN            NaN   \n",
      "1          NaN        NaN              NaN          NaN            NaN   \n",
      "2          NaN        NaN              NaN          NaN    22-Apr-2022   \n",
      "3          NaN        NaN              NaN          NaN    22-Apr-2022   \n",
      "4          NaN        NaN              NaN          NaN    22-Apr-2022   \n",
      "\n",
      "  exam_day exam_starttime  \n",
      "0      NaN            NaN  \n",
      "1      NaN            NaN  \n",
      "2      Fri          14:30  \n",
      "3      Fri          14:30  \n",
      "4      Fri          14:30  \n"
     ]
    }
   ],
   "source": [
    "# Set up folder path containing all Excel files\n",
    "data_folder = 'overallBossResultsWTimings'\n",
    "data_files = [os.path.join(data_folder, f) for f in os.listdir(data_folder)]\n",
    "\n",
    "# Load and combine data\n",
    "dataframes = [pd.read_csv(file) for file in data_files]\n",
    "data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Basic data checks\n",
    "print(f\"Loaded {len(data_files)} files.\")\n",
    "print(\"Initial Data Shape:\", data.shape)\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2463e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 1. Data Cleaning\n",
    "\n",
    "Steps:\n",
    "1. Remove rows where 'Min Bid' and 'Median Bid' == 0\n",
    "2. Drop redundant columns:\n",
    "    - `Session` - Removing 'Min Bid' and 'Median Bid' ==0 effectively transforms all sessions to 'Regular Academic Session'\n",
    "    - `D.I.C.E` - Nobody uses this\n",
    "    - `School/Department` - High correlation to 'SubjectArea'\n",
    "    - `Opening Vacancy` - Majority of the time is equals to 'Vacancy'. Redundant.\n",
    "    - `After Process Vacancy` - Future Dependent\n",
    "    - `Enrolled Students` - Future Dependent.\n",
    "3. Handle missing values (if any).\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "21f595d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning\n",
    "# 1. Remove rows where 'Min Bid' == 0 & 'Median Bid' == 0\n",
    "data = data[(data['Min Bid'] != 0) & (data['Median Bid'] != 0)]\n",
    "\n",
    "# 2. Drop redundant columns\n",
    "columns_to_drop = ['Session', 'D.I.C.E', 'School/Department', 'Opening Vacancy', 'Enrolled Students'] #'After Process Vacancy' will be removed later as we need to further clean data in outlier fixing.\n",
    "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# 3. Handle missing values\n",
    "data['Instructor'] = data['Instructor'].fillna(\"Not Assigned Yet\")\n",
    "\n",
    "# Fill empty or \"TBA\" values in specific columns with \"NA\"\n",
    "columns_with_na = [\n",
    "    'Grading Basis', 'class1_day', 'class1_starttime', 'class1_venue', \n",
    "    'class2_day', 'class2_starttime', 'class2_venue', \n",
    "    'class3_day', 'class3_starttime', 'class3_venue', \n",
    "    'exam_startdate', 'exam_day', 'exam_starttime'\n",
    "]\n",
    "\n",
    "for col in columns_with_na:\n",
    "    # Replace empty strings, NaN, or \"TBA\" with \"NA\"\n",
    "    data[col] = data[col].replace([\"\", \"TBA\", None], \"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8386abe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning categorical columns:\n",
      "   Grading Basis class1_day class1_starttime          class1_venue class2_day  \\\n",
      "45        Graded        Wed            15:30  SOA Seminar Room 3-5         NA   \n",
      "64        Graded        Mon            08:15  SOA Seminar Room 3-5         NA   \n",
      "65        Graded        Mon            15:30  SOA Seminar Room 3-5         NA   \n",
      "73        Graded        Thu            12:00  SOA Seminar Room 3-1         NA   \n",
      "96        Graded        Thu            19:00   LKCSB Classroom 2-1         NA   \n",
      "\n",
      "   class2_starttime class2_venue class3_day class3_starttime class3_venue  \\\n",
      "45               NA           NA         NA               NA           NA   \n",
      "64               NA           NA         NA               NA           NA   \n",
      "65               NA           NA         NA               NA           NA   \n",
      "73               NA           NA         NA               NA           NA   \n",
      "96               NA           NA         NA               NA           NA   \n",
      "\n",
      "   exam_startdate exam_day exam_starttime  \n",
      "45    20-Apr-2022      Wed          08:30  \n",
      "64    27-Apr-2022      Wed          08:30  \n",
      "65    27-Apr-2022      Wed          08:30  \n",
      "73    27-Apr-2022      Wed          13:00  \n",
      "96             NA       NA             NA  \n"
     ]
    }
   ],
   "source": [
    "print(f\"Data after cleaning categorical columns:\")\n",
    "print(data[columns_with_na].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae876e05",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 2. Feature Engineering\n",
    "\n",
    "Steps:\n",
    "1. Create `AY` and `Term` columns from `Term` column.\n",
    "2. Transform `Bidding Window` into `Round`, `Window`, `Incoming Freshman`, and `Incoming Exchange`.\n",
    "3. Split `Course Code` into `SubjectArea` and `CatalogueNo`.\n",
    "4. Removing invisible leading/trailing space in `Instructor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f94cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after Cleaning and Feature Engineering:\n",
      "   Term                       Description Section  Vacancy  \\\n",
      "45    2  Financial Reporting and Analysis      G3       42   \n",
      "64    2                         Valuation      G1       42   \n",
      "65    2                         Valuation      G2       42   \n",
      "73    2    Auditing for the Public Sector      G1       42   \n",
      "96    2          Public Relations Writing      G1       45   \n",
      "\n",
      "    Before Process Vacancy  After Process Vacancy  Median Bid  Min Bid  \\\n",
      "45                       3                      2       25.00    25.00   \n",
      "64                       9                      8       10.09    10.09   \n",
      "65                      12                     10       10.03    10.00   \n",
      "73                       7                      6       25.00    25.00   \n",
      "96                      10                      9       10.00    10.00   \n",
      "\n",
      "             Instructor Grading Basis class1_day class1_starttime  \\\n",
      "45         GOH BENG WEE        Graded        Wed            15:30   \n",
      "64       CHENG NAM SANG        Graded        Mon            08:15   \n",
      "65       CHENG NAM SANG        Graded        Mon            15:30   \n",
      "73         LIM SOO PING        Graded        Thu            12:00   \n",
      "96  YASMIN HANNAH RAMLE        Graded        Thu            19:00   \n",
      "\n",
      "            class1_venue class2_day class2_starttime class2_venue class3_day  \\\n",
      "45  SOA Seminar Room 3-5         NA               NA           NA         NA   \n",
      "64  SOA Seminar Room 3-5         NA               NA           NA         NA   \n",
      "65  SOA Seminar Room 3-5         NA               NA           NA         NA   \n",
      "73  SOA Seminar Room 3-1         NA               NA           NA         NA   \n",
      "96   LKCSB Classroom 2-1         NA               NA           NA         NA   \n",
      "\n",
      "   class3_starttime class3_venue exam_startdate exam_day exam_starttime    AY  \\\n",
      "45               NA           NA    20-Apr-2022      Wed          08:30  2021   \n",
      "64               NA           NA    27-Apr-2022      Wed          08:30  2021   \n",
      "65               NA           NA    27-Apr-2022      Wed          08:30  2021   \n",
      "73               NA           NA    27-Apr-2022      Wed          13:00  2021   \n",
      "96               NA           NA             NA       NA             NA  2021   \n",
      "\n",
      "   Incoming Freshman Incoming Exchange Round  Window SubjectArea CatalogueNo  \n",
      "45                no                no    2A       3        ACCT         224  \n",
      "64                no                no    2A       3        ACCT         336  \n",
      "65                no                no    2A       3        ACCT         336  \n",
      "73                no                no    2A       3        ACCT         409  \n",
      "96                no                no    2A       3        COMM         225  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 36718 entries, 45 to 121220\n",
      "Data columns (total 29 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Term                    36718 non-null  object \n",
      " 1   Description             36718 non-null  object \n",
      " 2   Section                 36718 non-null  object \n",
      " 3   Vacancy                 36718 non-null  int64  \n",
      " 4   Before Process Vacancy  36718 non-null  int64  \n",
      " 5   After Process Vacancy   36718 non-null  int64  \n",
      " 6   Median Bid              36718 non-null  float64\n",
      " 7   Min Bid                 36718 non-null  float64\n",
      " 8   Instructor              36718 non-null  object \n",
      " 9   Grading Basis           36718 non-null  object \n",
      " 10  class1_day              36718 non-null  object \n",
      " 11  class1_starttime        36718 non-null  object \n",
      " 12  class1_venue            36718 non-null  object \n",
      " 13  class2_day              36718 non-null  object \n",
      " 14  class2_starttime        36718 non-null  object \n",
      " 15  class2_venue            36718 non-null  object \n",
      " 16  class3_day              36718 non-null  object \n",
      " 17  class3_starttime        36718 non-null  object \n",
      " 18  class3_venue            36718 non-null  object \n",
      " 19  exam_startdate          36718 non-null  object \n",
      " 20  exam_day                36718 non-null  object \n",
      " 21  exam_starttime          36718 non-null  object \n",
      " 22  AY                      36718 non-null  int64  \n",
      " 23  Incoming Freshman       36718 non-null  object \n",
      " 24  Incoming Exchange       36718 non-null  object \n",
      " 25  Round                   36718 non-null  object \n",
      " 26  Window                  36718 non-null  int64  \n",
      " 27  SubjectArea             36718 non-null  object \n",
      " 28  CatalogueNo             36718 non-null  object \n",
      "dtypes: float64(2), int64(5), object(22)\n",
      "memory usage: 8.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering\n",
    "# Extract AY and Term\n",
    "data['AY'] = data['Term'].str[:4]\n",
    "data['Term'] = data['Term'].str.split('Term ', expand=True).str.strip()\n",
    "\n",
    "# Extract Round and Window from 'Bidding Window'\n",
    "# Example: 'Incoming Freshmen Rnd 1 Win 4'\n",
    "# Example: 'Incoming Exchange Rnd 1C Win 3'\n",
    "# Example: 'Round 2A Window 1'\n",
    "# Identify Incoming Freshmen and Exchange\n",
    "data['Incoming Freshman'] = data['Bidding Window'].str.contains('Incoming Freshmen', regex=True).map({True: 'yes', False: 'no'})\n",
    "data['Incoming Exchange'] = data['Bidding Window'].str.contains('Incoming Exchange', regex=True).map({True: 'yes', False: 'no'})\n",
    "\n",
    "# Extract Round (Handles both \"Round\" and \"Rnd\")\n",
    "data['Round'] = data['Bidding Window'].str.extract(r'(?:Round|Rnd) (\\d[A-C]?)')\n",
    "# Extract Window (Handles both \"Window\" and \"Win\")\n",
    "data['Window'] = data['Bidding Window'].str.extract(r'(?:Window|Win) (\\d)')\n",
    "\n",
    "# Extract SubjectArea and CatalogueNo from 'Course Code'\n",
    "data['SubjectArea'] = data['Course Code'].str.extract(r'([A-Za-z-]+)')\n",
    "data['CatalogueNo'] = data['Course Code'].str.extract(r'(\\d+)$')\n",
    "\n",
    "# Drop columns used for derived features\n",
    "data = data.drop(columns=['Bidding Window', 'Course Code'], errors='ignore')\n",
    "\n",
    "# After extracting AY and Window from strings, convert them to numeric\n",
    "data['AY'] = pd.to_numeric(data['AY'], errors='coerce')\n",
    "data['Window'] = pd.to_numeric(data['Window'], errors='coerce')\n",
    "\n",
    "# Remove leading and trailing space in `Instructor`\n",
    "data['Instructor'] = data['Instructor'].str.strip()\n",
    "\n",
    "print(\"Data after Cleaning and Feature Engineering:\")\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42f3b61",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "### Steps:\n",
    "1. Explore statistics and distributions of all variables.\n",
    "2. Perform corrleation heatmap on numerical variables. Perform feature selection afterwards to remove high multicollinear variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01fd7c1",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "07bcec8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Term                       object\n",
       "Description                object\n",
       "Section                    object\n",
       "Vacancy                     int64\n",
       "Before Process Vacancy      int64\n",
       "After Process Vacancy       int64\n",
       "Median Bid                float64\n",
       "Min Bid                   float64\n",
       "Instructor                 object\n",
       "Grading Basis              object\n",
       "class1_day                 object\n",
       "class1_starttime           object\n",
       "class1_venue               object\n",
       "class2_day                 object\n",
       "class2_starttime           object\n",
       "class2_venue               object\n",
       "class3_day                 object\n",
       "class3_starttime           object\n",
       "class3_venue               object\n",
       "exam_startdate             object\n",
       "exam_day                   object\n",
       "exam_starttime             object\n",
       "AY                          int64\n",
       "Incoming Freshman          object\n",
       "Incoming Exchange          object\n",
       "Round                      object\n",
       "Window                      int64\n",
       "SubjectArea                object\n",
       "CatalogueNo                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8bd18898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Descriptive Statistics (All Columns) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Description</th>\n",
       "      <th>Section</th>\n",
       "      <th>Vacancy</th>\n",
       "      <th>Before Process Vacancy</th>\n",
       "      <th>After Process Vacancy</th>\n",
       "      <th>Median Bid</th>\n",
       "      <th>Min Bid</th>\n",
       "      <th>Instructor</th>\n",
       "      <th>Grading Basis</th>\n",
       "      <th>class1_day</th>\n",
       "      <th>class1_starttime</th>\n",
       "      <th>class1_venue</th>\n",
       "      <th>class2_day</th>\n",
       "      <th>class2_starttime</th>\n",
       "      <th>class2_venue</th>\n",
       "      <th>class3_day</th>\n",
       "      <th>class3_starttime</th>\n",
       "      <th>class3_venue</th>\n",
       "      <th>exam_startdate</th>\n",
       "      <th>exam_day</th>\n",
       "      <th>exam_starttime</th>\n",
       "      <th>AY</th>\n",
       "      <th>Incoming Freshman</th>\n",
       "      <th>Incoming Exchange</th>\n",
       "      <th>Round</th>\n",
       "      <th>Window</th>\n",
       "      <th>SubjectArea</th>\n",
       "      <th>CatalogueNo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718.000000</td>\n",
       "      <td>36718.000000</td>\n",
       "      <td>36718.000000</td>\n",
       "      <td>36718.000000</td>\n",
       "      <td>36718.000000</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718.000000</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718.000000</td>\n",
       "      <td>36718</td>\n",
       "      <td>36718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>668</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>931</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>107</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2</td>\n",
       "      <td>Management Communication</td>\n",
       "      <td>G1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not Assigned Yet</td>\n",
       "      <td>Graded</td>\n",
       "      <td>Tue</td>\n",
       "      <td>12:00</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COR</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>20037</td>\n",
       "      <td>1394</td>\n",
       "      <td>14491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>516</td>\n",
       "      <td>31562</td>\n",
       "      <td>7168</td>\n",
       "      <td>10423</td>\n",
       "      <td>5485</td>\n",
       "      <td>35830</td>\n",
       "      <td>35830</td>\n",
       "      <td>35830</td>\n",
       "      <td>36661</td>\n",
       "      <td>36661</td>\n",
       "      <td>36661</td>\n",
       "      <td>13806</td>\n",
       "      <td>13806</td>\n",
       "      <td>13806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35563</td>\n",
       "      <td>32756</td>\n",
       "      <td>10295</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5469</td>\n",
       "      <td>2785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.654611</td>\n",
       "      <td>11.845852</td>\n",
       "      <td>5.509968</td>\n",
       "      <td>29.110291</td>\n",
       "      <td>24.532293</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022.612642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.520671</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.209872</td>\n",
       "      <td>12.406328</td>\n",
       "      <td>7.933868</td>\n",
       "      <td>20.306400</td>\n",
       "      <td>19.353522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.011167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.350000</td>\n",
       "      <td>10.502500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>24.820000</td>\n",
       "      <td>18.460000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>30.890000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4445.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>354.580000</td>\n",
       "      <td>354.580000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Term               Description Section       Vacancy  \\\n",
       "count   36718                     36718   36718  36718.000000   \n",
       "unique      4                       668      45           NaN   \n",
       "top         2  Management Communication      G1           NaN   \n",
       "freq    20037                      1394   14491           NaN   \n",
       "mean      NaN                       NaN     NaN     43.654611   \n",
       "std       NaN                       NaN     NaN     40.209872   \n",
       "min       NaN                       NaN     NaN      1.000000   \n",
       "25%       NaN                       NaN     NaN     45.000000   \n",
       "50%       NaN                       NaN     NaN     45.000000   \n",
       "75%       NaN                       NaN     NaN     45.000000   \n",
       "max       NaN                       NaN     NaN   4445.000000   \n",
       "\n",
       "        Before Process Vacancy  After Process Vacancy    Median Bid  \\\n",
       "count             36718.000000           36718.000000  36718.000000   \n",
       "unique                     NaN                    NaN           NaN   \n",
       "top                        NaN                    NaN           NaN   \n",
       "freq                       NaN                    NaN           NaN   \n",
       "mean                 11.845852               5.509968     29.110291   \n",
       "std                  12.406328               7.933868     20.306400   \n",
       "min                   0.000000               0.000000     10.000000   \n",
       "25%                   2.000000               0.000000     15.350000   \n",
       "50%                   6.000000               1.000000     24.820000   \n",
       "75%                  18.000000               8.000000     36.000000   \n",
       "max                  80.000000              64.000000    354.580000   \n",
       "\n",
       "             Min Bid        Instructor Grading Basis class1_day  \\\n",
       "count   36718.000000             36718         36718      36718   \n",
       "unique           NaN               931             3          8   \n",
       "top              NaN  Not Assigned Yet        Graded        Tue   \n",
       "freq             NaN               516         31562       7168   \n",
       "mean       24.532293               NaN           NaN        NaN   \n",
       "std        19.353522               NaN           NaN        NaN   \n",
       "min        10.000000               NaN           NaN        NaN   \n",
       "25%        10.502500               NaN           NaN        NaN   \n",
       "50%        18.460000               NaN           NaN        NaN   \n",
       "75%        30.890000               NaN           NaN        NaN   \n",
       "max       354.580000               NaN           NaN        NaN   \n",
       "\n",
       "       class1_starttime class1_venue class2_day class2_starttime class2_venue  \\\n",
       "count             36718        36718      36718            36718        36718   \n",
       "unique               11          107          6                8           54   \n",
       "top               12:00           NA         NA               NA           NA   \n",
       "freq              10423         5485      35830            35830        35830   \n",
       "mean                NaN          NaN        NaN              NaN          NaN   \n",
       "std                 NaN          NaN        NaN              NaN          NaN   \n",
       "min                 NaN          NaN        NaN              NaN          NaN   \n",
       "25%                 NaN          NaN        NaN              NaN          NaN   \n",
       "50%                 NaN          NaN        NaN              NaN          NaN   \n",
       "75%                 NaN          NaN        NaN              NaN          NaN   \n",
       "max                 NaN          NaN        NaN              NaN          NaN   \n",
       "\n",
       "       class3_day class3_starttime class3_venue exam_startdate exam_day  \\\n",
       "count       36718            36718        36718          36718    36718   \n",
       "unique          4                5            7             83        7   \n",
       "top            NA               NA           NA             NA       NA   \n",
       "freq        36661            36661        36661          13806    13806   \n",
       "mean          NaN              NaN          NaN            NaN      NaN   \n",
       "std           NaN              NaN          NaN            NaN      NaN   \n",
       "min           NaN              NaN          NaN            NaN      NaN   \n",
       "25%           NaN              NaN          NaN            NaN      NaN   \n",
       "50%           NaN              NaN          NaN            NaN      NaN   \n",
       "75%           NaN              NaN          NaN            NaN      NaN   \n",
       "max           NaN              NaN          NaN            NaN      NaN   \n",
       "\n",
       "       exam_starttime            AY Incoming Freshman Incoming Exchange  \\\n",
       "count           36718  36718.000000             36718             36718   \n",
       "unique              4           NaN                 2                 2   \n",
       "top                NA           NaN                no                no   \n",
       "freq            13806           NaN             35563             32756   \n",
       "mean              NaN   2022.612642               NaN               NaN   \n",
       "std               NaN      1.011167               NaN               NaN   \n",
       "min               NaN   2021.000000               NaN               NaN   \n",
       "25%               NaN   2022.000000               NaN               NaN   \n",
       "50%               NaN   2023.000000               NaN               NaN   \n",
       "75%               NaN   2023.000000               NaN               NaN   \n",
       "max               NaN   2024.000000               NaN               NaN   \n",
       "\n",
       "        Round        Window SubjectArea CatalogueNo  \n",
       "count   36718  36718.000000       36718       36718  \n",
       "unique      6           NaN          55         373  \n",
       "top         1           NaN         COR         101  \n",
       "freq    10295           NaN        5469        2785  \n",
       "mean      NaN      1.520671         NaN         NaN  \n",
       "std       NaN      0.658304         NaN         NaN  \n",
       "min       NaN      1.000000         NaN         NaN  \n",
       "25%       NaN      1.000000         NaN         NaN  \n",
       "50%       NaN      1.000000         NaN         NaN  \n",
       "75%       NaN      2.000000         NaN         NaN  \n",
       "max       NaN      5.000000         NaN         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Print descriptive statistics for all columns\n",
    "print(\"=== Descriptive Statistics (All Columns) ===\")\n",
    "display(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff63e6ea",
   "metadata": {},
   "source": [
    "### Outlier fixing\n",
    "\n",
    "1. There are three rows affected with vacancy of 4445. Replace with 45."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e88e87d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all rows where Vacancy is 4445 with 45\n",
    "data.loc[data['Vacancy'] == 4445, 'Vacancy'] = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1148c42",
   "metadata": {},
   "source": [
    "2. Min bid prices for certain classes are high because of troll bidding / graduation.\n",
    "\n",
    "- This is likely caused by people who bidded by themselves only. We can remove these rows as they skew the model and is not representative of majority of the cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "1b0214e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36718.000000\n",
       "mean        24.532293\n",
       "std         19.353522\n",
       "min         10.000000\n",
       "25%         10.502500\n",
       "50%         18.460000\n",
       "75%         30.890000\n",
       "max        354.580000\n",
       "Name: Min Bid, dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Min Bid'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5efc3dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36718.000000\n",
       "mean        29.110291\n",
       "std         20.306400\n",
       "min         10.000000\n",
       "25%         15.350000\n",
       "50%         24.820000\n",
       "75%         36.000000\n",
       "max        354.580000\n",
       "Name: Median Bid, dtype: float64"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Median Bid'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9c5756ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.471250000000005"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iqrMinBid = data['Min Bid'].quantile(0.75) - data['Min Bid'].quantile(0.25)\n",
    "outlierThresholdMinBid = data['Min Bid'].quantile(0.75) + iqrMinBid * 1.5\n",
    "outlierThresholdMinBid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "96989467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Round  Window  Count\n",
      "0      1       1     27\n",
      "1      1       2     83\n",
      "2     1A       1    121\n",
      "3     1A       2    171\n",
      "4     1A       3     50\n",
      "5     1B       1    143\n",
      "6     1B       2    126\n",
      "7     1C       1     12\n",
      "8     1C       2      2\n",
      "9     1C       3      1\n",
      "10     2       1    129\n",
      "11     2       2     61\n",
      "12     2       3     23\n",
      "13    2A       1     13\n",
      "14    2A       2     14\n",
      "15    2A       3      8\n"
     ]
    }
   ],
   "source": [
    "# Filter data for Min Bid > 60 and Before Process Vacancy - After Process Vacancy = 1\n",
    "high_bid_data = data[(data['Min Bid'] > outlierThresholdMinBid) & \n",
    "                     ((data['Before Process Vacancy'] - data['After Process Vacancy']) == 1)]\n",
    "\n",
    "# Count unique combinations of 'Round' and 'Window'\n",
    "round_window_counts = high_bid_data.groupby(['Round', 'Window']).size().reset_index(name='Count')\n",
    "\n",
    "# Display the counts\n",
    "print(round_window_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "79c21705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify rows that meet both conditions\n",
    "dropOutliersMinBid = data[(data['Min Bid'] >= outlierThresholdMinBid) & \n",
    "                           ((data['Before Process Vacancy'] - data['After Process Vacancy']) == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ee8f19af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows to be dropped\n",
    "num_dropped_rows = len(dropOutliersMinBid)\n",
    "\n",
    "# Drop these rows from the dataset\n",
    "data = data.drop(dropOutliersMinBid.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "a453a066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 984 rows where 'Min Bid' >= 61.471250000000005 and 'Before Process Vacancy - After Process Vacancy' == 1.\n"
     ]
    }
   ],
   "source": [
    "# Print the number of rows removed\n",
    "print(f\"Removed {num_dropped_rows} rows where 'Min Bid' >= {outlierThresholdMinBid} and 'Before Process Vacancy - After Process Vacancy' == 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ed18f77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    35734.000000\n",
       "mean        22.706312\n",
       "std         15.130064\n",
       "min         10.000000\n",
       "25%         10.300000\n",
       "50%         17.890000\n",
       "75%         30.000000\n",
       "max        261.000000\n",
       "Name: Min Bid, dtype: float64"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Min Bid'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "53cad5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsSElEQVR4nO3df3BU9b3/8ddmE0IS8oMAmx8lgVwiAiUKIo0Z+RGEJATkNgZmitXWX1dHGpyvhloabqvSOuSOo9hvHZTpvbfSGYV6xZVeU+CSIiRLS0SpfCEICEz4ofnFryTkJ5vNfv/wm/2yhmp+bDgnu8/HTIY957x3971/nN0Xn3PO51jcbrdbAAAAJhJkdAMAAABfR0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmE2x0A/3R1dWl6upqRUZGymKxGN0OAADoBbfbratXryoxMVFBQd88RjIkA0p1dbWSkpKMbgMAAPTD+fPnNXbs2G+sGZIBJTIyUtJXHzAqKsrgbgD4ktPp1K5du5Sdna2QkBCj2wHgQ01NTUpKSvL8jn+TIRlQug/rREVFEVAAP+N0OhUeHq6oqCgCCuCnenN6BifJAgAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgADANl8ulsrIylZeXq6ysTC6Xy+iWABiEgALAFOx2u1JTU5WVlaX169crKytLqampstvtRrcGwAAEFACGs9vtWrZsmdLS0uRwOLRlyxY5HA6lpaVp2bJlhBQgAFncbrfb6Cb6qqmpSdHR0WpsbORePMAQ53K5lJqaqrS0NG3btk0ul0vbt2/XokWLZLValZeXp8rKSp08eVJWq9XodgEMQF9+vxlBAWAoh8OhM2fOaM2aNQoK8v5KCgoKUlFRkaqqquRwOAzqEIARCCgADFVTUyNJmjp16g23d6/vrgMQGAgoAAyVkJAgSaqsrLzh9u713XUAAgMBBYChZs+erfHjx2vdunXq6ury2tbV1aXi4mKlpKRo9uzZBnUIwAgEFACGslqteuWVV1RSUqK8vDxVVFSora1NFRUVysvLU0lJiV5++WVOkAUCTLDRDQBAfn6+tm7dqlWrVmnOnDme9SkpKdq6davy8/MN7A6AEbjMGIBpuFwu7dmzRzt27FBubq7mzZvHyAngR/ry+80ICgDTsFqtmjt3rlpaWjR37lzCCRDAOAcFAACYDgEFAACYDgEFAACYDgEFAACYTp8CSnFxsWbOnKnIyEjZbDbl5eXpxIkTXjWZmZmyWCxef08++aRXzblz57R48WKFh4fLZrPp2WefVWdn58A/DQAA8At9uoqnrKxMBQUFmjlzpjo7O7VmzRplZ2frs88+U0REhKfu8ccf169+9SvPcnh4uOexy+XS4sWLFR8fr7/97W+qqanRj3/8Y4WEhGjdunU++EgAAGCo61NA2blzp9fypk2bZLPZdPDgQa/JlcLDwxUfH3/D19i1a5c+++wz/eUvf1FcXJymTZumX//611q9erVeeOEFDRs2rB8fAwAA+JMBzYPS2NgoSYqNjfVa//bbb+utt95SfHy8lixZol/+8peeUZT9+/crLS1NcXFxnvqcnBytWLFCR48e1fTp03u8T0dHhzo6OjzLTU1NkiSn0ymn0zmQjwDAZLr3afZtwP/0Zb/ud0Dp6urS008/rbvvvtvrNuk//OEPNW7cOCUmJurw4cNavXq1Tpw4IbvdLkmqra31CieSPMu1tbU3fK/i4mKtXbu2x/pdu3Z5HT4C4D9KS0uNbgGAj7W2tva6tt8BpaCgQJWVldq3b5/X+ieeeMLzOC0tTQkJCZo/f75Onz6tCRMm9Ou9ioqKVFhY6FluampSUlKSsrOzmeoe8DNOp1OlpaXKyspSSEiI0e0A8KHuIyC90a+AsnLlSpWUlKi8vFxjx479xtr09HRJ0qlTpzRhwgTFx8frwIEDXjV1dXWS9A/PWwkNDVVoaGiP9SEhIXyBAX6K/RvwP33Zp/t0mbHb7dbKlSv1/vvv68MPP1RKSsq3PufQoUOSpISEBElSRkaGjhw5ovr6ek9NaWmpoqKiNGXKlL60AwAA/FSfRlAKCgq0efNm/elPf1JkZKTnnJHo6GiFhYXp9OnT2rx5sxYtWqRRo0bp8OHDeuaZZzRnzhzddtttkqTs7GxNmTJFP/rRj/TSSy+ptrZWv/jFL1RQUHDDURIAABB4+jSC8sYbb6ixsVGZmZlKSEjw/L3zzjuSpGHDhukvf/mLsrOzNWnSJK1atUpLly7VBx984HkNq9WqkpISWa1WZWRk6MEHH9SPf/xjr3lTAABAYOvTCIrb7f7G7UlJSSorK/vW1xk3bpy2b9/el7cGAAABhHvxAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgAAAA0yGgADANl8ulsrIylZeXq6ysTC6Xy+iWABiEgALAFOx2u1JTU5WVlaX169crKytLqampstvtRrcGwAAEFACGs9vtWrZsmdLS0uRwOLRlyxY5HA6lpaVp2bJlhBQgAFncbrfb6Cb6qqmpSdHR0WpsbFRUVJTR7QAYAJfLpdTUVKWlpWnbtm1yuVzavn27Fi1aJKvVqry8PFVWVurkyZOyWq1GtwtgAPry+80ICgBDORwOnTlzRmvWrFFQkPdXUlBQkIqKilRVVSWHw2FQhwCMQEABYKiamhpJ0tSpU2+4vXt9dx2AwEBAAWCohIQESVJlZeUNt3ev764DEBgIKAAMNXv2bI0fP17r1q1TV1eX17auri4VFxcrJSVFs2fPNqhDAEYgoAAwlNVq1SuvvKKSkhLl5eWpoqJCbW1tqqioUF5enkpKSvTyyy9zgiwQYIKNbgAA8vPztXXrVq1atUpz5szxrE9JSdHWrVuVn59vYHcAjMBlxgBMw+Vyac+ePdqxY4dyc3M1b948Rk4AP9KX329GUACYhtVq1dy5c9XS0qK5c+cSToAAxjkoAADAdAgoAADAdAgoAADAdPoUUIqLizVz5kxFRkbKZrMpLy9PJ06c8Kppb29XQUGBRo0apREjRmjp0qWqq6vzqjl37pwWL16s8PBw2Ww2Pfvss+rs7Bz4pwEAAH6hTwGlrKxMBQUFqqioUGlpqZxOp7Kzs9XS0uKpeeaZZ/TBBx/o3XffVVlZmaqrq70uEXS5XFq8eLGuXbumv/3tb/rDH/6gTZs26bnnnvPdpwIAAEPagC4zvnDhgmw2m8rKyjRnzhw1NjZqzJgx2rx5s5YtWyZJOn78uCZPnqz9+/frrrvu0o4dO3TvvfequrpacXFxkqSNGzdq9erVunDhgoYNG/at78tlxoD/cjqdnrsZh4SEGN0OAB+6aZcZNzY2SpJiY2MlSQcPHpTT6dSCBQs8NZMmTVJycrInoOzfv19paWmecCJJOTk5WrFihY4eParp06f3eJ+Ojg51dHR4fUDpqy8yp9M5kI8AwGS692n2bcD/9GW/7ndA6erq0tNPP627777bc7fR2tpaDRs2TDExMV61cXFxqq2t9dRcH066t3dvu5Hi4mKtXbu2x/pdu3YpPDy8vx8BgImVlpYa3QIAH2ttbe11bb8DSkFBgSorK7Vv377+vkSvFRUVqbCw0LPc1NSkpKQkZWdnc4gH8DNOp1OlpaXKysriEA/gZ7qPgPRGvwLKypUrVVJSovLyco0dO9azPj4+XteuXVNDQ4PXKEpdXZ3i4+M9NQcOHPB6ve6rfLprvi40NFShoaE91oeEhPAFBvgp9m/A//Rln+7TVTxut1srV67U+++/rw8//FApKSle22fMmKGQkBDt3r3bs+7EiRM6d+6cMjIyJEkZGRk6cuSI6uvrPTWlpaWKiorSlClT+tIOAADwU30aQSkoKNDmzZv1pz/9SZGRkZ5zRqKjoxUWFqbo6Gg99thjKiwsVGxsrKKiovTUU08pIyNDd911lyQpOztbU6ZM0Y9+9CO99NJLqq2t1S9+8QsVFBTccJQEAAAEnj4FlDfeeEOSlJmZ6bX+zTff1MMPPyxJevXVVxUUFKSlS5eqo6NDOTk5ev311z21VqtVJSUlWrFihTIyMhQREaGHHnpIv/rVrwb2SQAAgN8Y0DwoRmEeFMB/MQ8K4L/68vvNvXgAAIDpEFAAAIDpEFAAAIDpEFAAAIDpEFAAAIDpEFAAAIDpEFAAmIbL5VJZWZnKy8tVVlYml8tldEsADEJAAWAKdrtdqampysrK0vr165WVlaXU1FTZ7XajWwNgAAIKAMPZ7XYtW7ZMaWlpcjgc2rJlixwOh9LS0rRs2TJCChCAmEkWgKFcLpdSU1OVlpambdu2yeVyeWaStVqtysvLU2VlpU6ePCmr1Wp0uwAGgJlkAQwZDodDZ86c0Zo1axQU5P2VFBQUpKKiIlVVVcnhcBjUIQAjEFAAGKqmpkaSNHXq1Btu717fXQcgMBBQABgqISFBklRZWXnD7d3ru+sABAYCCgBDzZ49W+PHj9e6devU1dXlta2rq0vFxcVKSUnR7NmzDeoQgBEIKAAMZbVa9corr6ikpER5eXmqqKhQW1ubKioqlJeXp5KSEr388sucIAsEmGCjGwCA/Px8bd26VatWrdKcOXM861NSUrR161bl5+cb2B0AI3CZMQDTcLlc2rNnj3bs2KHc3FzNmzePkRPAj3CZMQAAGNIIKABMwW63a8KECV5T3U+YMIFZZIEARUABYDi73a6lS5eqvr7ea319fb2WLl1KSAECEAEFgKFcLpeefPJJSdL8+fO97sUzf/58SdKKFSu4szEQYAgoAAy1d+9eXbhwQbNmzZLdbld7e7s+/vhjtbe3y263a9asWaqvr9fevXuNbhXATURAAWCo7uCxYMECTZw40esclIkTJ3pGUQgoQGAhoAAwhRdeeEFpaWleh3jS0tK0du1ao1sDYAAmagNgqO6J2UaOHCm73S63261Lly4pPT1ddrtdNptNV65c8ZrADYD/YwQFgKGCgr76Grpy5Yruu+8+r6nu77vvPl25csWrDkBgYAQFgKG6Ly22WCzavXu3SkpKPNvCwsJksVjkdrt7XIIMwL/xXxIAhkpISJAk/fCHP9S1a9e8tjmdTt1///1edQACA/fiAWAol8ulhIQEXbhwQcOHD1d7e7tnW/eyzWZTdXU19+UBhri+/H5ziAeA4bpHTqKiovTqq696gsnzzz+v9vZ2dXR0GNwhgJuNgALAUHv37lVjY6MmTZqktrY2rVixwrNt/PjxmjRpko4fP669e/d65kQB4P84BwWAobonYNuwYYNOnz6t0tJSFRYWqrS0VKdOndJrr73mVQcgMDCCAsA0rFar5s6dq5aWFs2dO5dzToAAxggKAENlZmZKkp5//nl1dXV5bevq6vLMJNtdByAwEFAAGCozM1NjxozRvn379P3vf99rorbvf//72rdvn2w2GwEFCDAc4gFgKKvVqo0bN2rp0qU9JmoLDw+XJL3xxhsc7gECDCMoAAyXn5+v9957TzabzWu9zWbTe++9p/z8fIM6A2AUJmoDYBoul0t79uzRjh07lJubq3nz5jFyAvgRJmoDMCRxFQ+AbhziAQAApkNAAQAApkNAAQAApkNAAQAApkNAAQAApkNAAQAApkNAAQAApkNAAQAApkNAAQAApkNAAQAApkNAAQAApkNAAWAaLpdLZWVlKi8vV1lZmVwul9EtATAIAQWAKdjtdqWmpiorK0vr169XVlaWUlNTZbfbjW4NgAEIKAAMZ7fbtWzZMqWlpcnhcGjLli1yOBxKS0vTsmXLCClAALK43W630U30VVNTk6Kjo9XY2KioqCij2wEwAC6XS6mpqUpLS9O2bdvkcrm0fft2LVq0SFarVXl5eaqsrNTJkydltVqNbhfAAPTl95sRFACGcjgcOnPmjNasWaOgIO+vpKCgIBUVFamqqkoOh8OgDgEYIdjoBgAEtpqaGknS1KlT1djYqNzcXJ08eVK33HKLduzYoalTp3rVAQgMfR5BKS8v15IlS5SYmCiLxaJt27Z5bX/44YdlsVi8/hYuXOhVc/nyZT3wwAOKiopSTEyMHnvsMTU3Nw/ogwAYmhISEiRJkyZNUkxMjPbv36+LFy9q//79iomJ0eTJk73qAASGPgeUlpYW3X777dqwYcM/rFm4cKFqamo8f1u2bPHa/sADD+jo0aMqLS1VSUmJysvL9cQTT/S9ewBD3uzZsxUcHKwvv/xSkpSTk6N/+7d/U05OjiTpyy+/VHBwsGbPnm1kmwBusj4f4snNzVVubu431oSGhio+Pv6G244dO6adO3fq448/1p133ilJeu2117Ro0SK9/PLLSkxM7GtLAIaw5uZmdXZ2Svrq+6WoqEhffvml/vVf/1VBQUHasWOHOjs71dzcrOjoaIO7BXCzDMo5KHv37pXNZtPIkSN1zz336MUXX9SoUaMkyTNs2x1OJGnBggUKCgrSRx99pPvuu6/H63V0dKijo8Oz3NTUJElyOp1yOp2D8REA3CTd/+GZNm2ajh07pjlz5ni2paSk6LbbbtPhw4eVm5ursrIyo9oE4AN9+c32eUBZuHCh8vPzlZKSotOnT2vNmjXKzc3V/v37ZbVaVVtbK5vN5t1EcLBiY2NVW1t7w9csLi7W2rVre6zftWuXwsPDff0RANxEJ0+elCQtX75ct9xyiz777DNduXJFI0eO1JQpU3T8+HEdPnxYJ0+e1Pbt2w3uFsBAtLa29rrW5wFl+fLlnsdpaWm67bbbNGHCBO3du1fz58/v12sWFRWpsLDQs9zU1KSkpCRlZ2czDwowxN1yyy26ePGi9uzZo8LCQi1cuFClpaXKyspSSEiINm7c6KlbtGiRwd0CGIjuIyC9MeiXGf/TP/2TRo8erVOnTmn+/PmKj49XfX29V01nZ6cuX778D89bCQ0NVWhoaI/1ISEhCgkJGZS+AdwcO3bsUExMjP7nf/5HTqfTs0+HhITI6XSqtLTUU8f+DgxtfdmHB32iti+++EKXLl3yXCKYkZGhhoYGHTx40FPz4YcfqqurS+np6YPdDgCTiY6O1oQJEyRJERERysjI0ObNm5WRkaGIiAhJ0oQJEzhBFggwfZ7qvrm5WadOnZIkTZ8+XevXr9e8efMUGxur2NhYrV27VkuXLlV8fLxOnz6tn/3sZ7p69aqOHDniGQXJzc1VXV2dNm7cKKfTqUceeUR33nmnNm/e3KsemOoe8D/x8fGqq6vrsT4uLu4fnp8GYGgZ1KnuP/nkE02fPl3Tp0+XJBUWFmr69Ol67rnnZLVadfjwYf3zP/+zJk6cqMcee0wzZsyQw+HwOkTz9ttva9KkSZo/f74WLVqkWbNm6Xe/+11fWwHgJ+x2u+rr65WTk6Px48crIiJC48ePV05Ojurr67lZIBCAuFkgAEN13yxw9OjRunjxos6cOePZNn78eI0ePVqXLl3iZoGAH+jL7zf34gFgqO6bBZ49e1aLFy9WYWGhPv/8c02cOFG7du3Sn//8Z7ndbjkcDmVmZhrdLoCbhIACwFDdU9xPmzZNR44cUUlJiWfbuHHjNG3aNH366aeeOgCBgYACwFAXLlyQJH366ac9tp09e1Znz571qgMQGAgoAAzVfRsM6as5Ep555hmlpKSoqqpKr776qmdq7OvrAPi/QZ8HBQC+SXV1tedxVlaW7r33XsXExOjee+9VVlbWDesA+D9GUAAYqnumWJvNpqNHj3rdLHD8+PGy2Wyqr69XaWmpVq9ebVSbAG4yAgoAQzU2NkqS6uvrtXjxYi1ZssRzFU9VVZX+/Oc/e9UBCAwEFACGmjlzpj755BPFxMRo586dcrlckr66W7nValVMTIwaGho0c+ZMgzsFcDMxURsAQ7W1tSk8PFySNGbMGM2ZM0dXrlzRyJEjVV5e7rl6p7W1VWFhYUa2CmCAmKgNwJAxbNgwhYWFqa2tTRcuXNB7773XoyYsLEzDhg0zoDsARuEqHgCGcjgcamtr+8aatrY2ORyOm9QRADMgoAAw1PUzxIaEhHhtu36ZmWSBwEJAAWCo2tpaz+OcnBw5HA5t2bJFDodDOTk5N6wD4P84BwWAoS5duiRJiomJ0fvvvy+3261Lly4pPT1d77//vsaMGaOGhgZPHYDAwAgKAEOdP39ektTQ0KD8/HxVVFSora1NFRUVys/PV0NDg1cdgMDACAoAQyUnJ0uSJk6cqEOHDnnNJJucnKyJEyfq888/99QBCAyMoAAw1D333CNJ+vzzz3uMkpw7d06ff/65Vx2AwEBAAWCozMzMb52ALSwsTJmZmTenIQCmQEABYCiXy9WreVC6p8AHEBgIKAAM9eqrr0qSLBaLgoK8v5KCgoJksVi86gAEBgIKAEO99dZbkiS3291jOvthw4ap+3Zh3XUAAgMBBYChrl275nnc0dHhte365evrAPg/AgoAQ91yyy0+rQPgHwgoAAx16623eh53H8650fL1dQD8HwEFgKEOHz7s0zoA/oGAAsBQV69e9WkdAP9AQAFgqMuXL3se3+gy4xvVAfB/BBQAhhoxYoTncVdXl9e265evrwPg/wgoAAz1ne98x6d1APwDAQWAoaZMmeLTOgD+gYACwFBnz571aR0A/0BAAWCoo0eP+rQOgH8goAAw1LFjxzyPhw8f7rXt+uXr6wD4PwIKAENdP1tse3u717brl78+yywA/0ZAAWCoUaNG+bQOgH8goAAw1GuvvebTOgD+gYACwFCVlZU+rQPgHwgoAADAdAgoAAw1Z84cSVJERITGjh3rtW3s2LGKiIjwqgMQGIKNbgBAYOu+IWBLS4va2tq8tlVXV3vux/P1GwkC8G/s8QAMVVtb63n8TTcLvL4OgP8joAAwVG+DBwEFCCwEFACGunTpkk/rAPgHAgoAQ505c8andQD8AwEFgKGOHz/u0zoA/oGAAsBQjY2NPq0D4B8IKAAM1dDQ4NM6AP6BgALAUB0dHT6tA+AfCCgADOVyuXxaB8A/EFAAGMpqtfq0DoB/IKAAMNSIESN8WgfAPxBQABhq5MiRPq0D4B8IKAAM9fX77wy0DoB/IKAAMFR1dbVP6wD4BwIKAENdu3bNp3UA/AMBBYChLBaLT+sA+Ic+B5Ty8nItWbJEiYmJslgs2rZtm9d2t9ut5557TgkJCQoLC9OCBQt08uRJr5rLly/rgQceUFRUlGJiYvTYY4+publ5QB8EwNAUEhLi0zoA/qHPAaWlpUW33367NmzYcMPtL730kn77299q48aN+uijjxQREaGcnBy1t7d7ah544AEdPXpUpaWlKikpUXl5uZ544on+fwoAQ5bNZvNpHQD/YHG73e5+P9li0fvvv6+8vDxJX42eJCYmatWqVfrpT38q6asbfMXFxWnTpk1avny5jh07pilTpujjjz/WnXfeKUnauXOnFi1apC+++EKJiYnf+r5NTU2Kjo5WY2OjoqKi+ts+ABOIi4tTfX39t9bZbDbV1dXdhI4ADJa+/H4H+/KNq6qqVFtbqwULFnjWRUdHKz09Xfv379fy5cu1f/9+xcTEeMKJJC1YsEBBQUH66KOPdN999/V43Y6ODq/7cDQ1NUmSnE6nnE6nLz8CgJusN+Gku479HRja+rIP+zSg1NbWSvrqf0TXi4uL82yrra3tMVQbHBys2NhYT83XFRcXa+3atT3W79q1S+Hh4b5oHcAQsH37dqNbADAAra2tva71aUAZLEVFRSosLPQsNzU1KSkpSdnZ2RziAQLIokWLjG4BwAB0HwHpDZ8GlPj4eElSXV2dEhISPOvr6uo0bdo0T83Xh3Q7Ozt1+fJlz/O/LjQ0VKGhoT3Wh4SEcGY/MMRFRkbq6tWrvapjfweGtr7swz6dByUlJUXx8fHavXu3Z11TU5M++ugjZWRkSJIyMjLU0NCggwcPemo+/PBDdXV1KT093ZftABgCOjs7fVoHwD/0eQSlublZp06d8ixXVVXp0KFDio2NVXJysp5++mm9+OKLuuWWW5SSkqJf/vKXSkxM9FzpM3nyZC1cuFCPP/64Nm7cKKfTqZUrV2r58uW9uoIHgH8ZMWKE2traelUHIHD0OaB88sknmjdvnme5+9yQhx56SJs2bdLPfvYztbS06IknnlBDQ4NmzZqlnTt3avjw4Z7nvP3221q5cqXmz5+voKAgLV26VL/97W998HEADDUjR47UhQsXelUHIHAMaB4UozAPCuA/YmJi1NjY+K110dHRamhoGPyGAAyavvx+cy8eAIbqzQmyfakD4B8IKAAM1dXV5dM6AP6BgAIAAEyHgALAUFar1ad1APwDAQWAoa6/ws8XdQD8AwEFgKFaWlp8WgfAPxBQAACA6RBQAACA6RBQAACA6RBQAACA6RBQABgqIiLCp3UA/AMBBYChWltbfVoHwD8QUAAYqrf3Kx2C9zUFMAAEFAAAYDoEFAAAYDoEFACG4l48AG6EgALAUF1dXT6tA+AfCCgADMVJsgBuhIACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMh4ACAABMJ9joBgAMfa2trTp+/Pigv8/f//73fj1v0qRJCg8P93E3AAYTAQXAgB0/flwzZswY9Pfp73scPHhQd9xxh4+7ATCYCCgABmzSpEk6ePBgv57bl9DR3/eYNGlSv54HwDgEFAADFh4e3u8RCpvNpvr6+l7VMQoCBA5OkgVgqLq6Op/WAfAPBBQAhnO73QPaDsD/EFAAmILb7ZbNZvNaZ7PZCCdAgCKgADCNuro6fXrmosatLtGnZy5yWAcIYAQUAABgOgQUAABgOj4PKC+88IIsFovX3/VzELS3t6ugoECjRo3SiBEjtHTpUoZxAQCAl0EZQfnud7+rmpoaz9++ffs825555hl98MEHevfdd1VWVqbq6mrl5+cPRhsAAGCIGpSJ2oKDgxUfH99jfWNjo/7zP/9Tmzdv1j333CNJevPNNzV58mRVVFTorrvuGox2AADAEDMoAeXkyZNKTEzU8OHDlZGRoeLiYiUnJ+vgwYNyOp1asGCBp3bSpElKTk7W/v37/2FA6ejoUEdHh2e5qalJkuR0OuV0OgfjIwAwSGdnp+df9m/Av/Rln/Z5QElPT9emTZt06623qqamRmvXrtXs2bNVWVmp2tpaDRs2TDExMV7PiYuLU21t7T98zeLiYq1du7bH+l27dnGHUsDPnG+WpGBVVFToy0qjuwHgS62trb2u9XlAyc3N9Ty+7bbblJ6ernHjxum//uu/FBYW1q/XLCoqUmFhoWe5qalJSUlJys7OVlRU1IB7BmAe/+fcZenIJ7rrrrt0e3Ks0e0A8KHuIyC9Meg3C4yJidHEiRN16tQpZWVl6dq1a2poaPAaRamrq7vhOSvdQkNDFRoa2mN9SEiIQkJCBqNtAAYJDg72/Mv+DfiXvuzTgz4PSnNzs06fPq2EhATNmDFDISEh2r17t2f7iRMndO7cOWVkZAx2KwAAYIjw+QjKT3/6Uy1ZskTjxo1TdXW1nn/+eVmtVt1///2Kjo7WY489psLCQsXGxioqKkpPPfWUMjIyuIIHAAB4+DygfPHFF7r//vt16dIljRkzRrNmzVJFRYXGjBkjSXr11VcVFBSkpUuXqqOjQzk5OXr99dd93QYAABjCfB5Q/vjHP37j9uHDh2vDhg3asGGDr98aAAD4Ce7FAwAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATIeAAgAATCfY6AYAGKvqYotaOjqNbsPj9IUWz7/Bweb5iooIDVbK6Aij2wAChnn2fgA3XdXFFs17ea/RbdzQqq1HjG6hhz0/zSSkADcJAQUIYN0jJ7/5wTSl2kYY3M1XWto6VLJ3v+7NzFBEWKjR7UiSTtU36+l3DplqpAnwdwQUAEq1jdDU70Qb3YYkyel0qnaMdMe4kQoJCTG6HQAG4SRZAABgOgQUAABgOgQUAABgOgQUAABgOgQUAABgOgQUAABgOgQUAABgOgQUAABgOgQUAABgOgQUAABgOgQUAABgOgQUAABgOtwsEAhgHa52BQ3/UlVNJxQ03Bx3M+7s7FR1Z7WOXT6m4GBzfEVVNTUraPiX6nC1SzLHTRUBf2eOvR+AIapbzioi5TWtOWB0Jz29vvN1o1vwEpEiVbdM0wzFGd0KEBAIKEAAS4wYp5aqp/S/fzBNE2zmGUH5676/6u5Zd5tmBOV0fbP+1zuHlDhvnNGtAAHDHHs/AEOEWoerq/07Som6VVNGmePQhdPpVFVwlSbHTlZISIjR7UiSutob1dV+QaHW4Ua3AgQMTpIFAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmw2XGQABrc7okSZVfNg7sddpaVXXqc1+0JJfLpUNHTqs12CGr1eqT10xJnaiwsPB+P/9UfbNP+gDQewQUIICd/n8/vD+3HxnQ63TUnlLtH572QUeDI/6h3yg0PnXArxMRylcmcLOwtwEBLPu78ZKkCbYRCgvp/2hFW9sdqlo+zSc9uVwuHfr0kKZNn2aaERTpq3CSMjrCJ/0A+HYEFCCAxUYM0/LvJfvglaI1MzXBB6/z1Uyy4Z1XtSh7tmlmkgVw83GSLAAAMB0CCgAAMB0CCgAAMB0CCgAAMB0CCgAAMB0CCgAAMB0CCgAAMB1DA8qGDRs0fvx4DR8+XOnp6Tpw4ICR7QAAAJMwLKC88847Kiws1PPPP6+///3vuv3225WTk6P6+nqjWgIAACZhWEBZv369Hn/8cT3yyCOaMmWKNm7cqPDwcP3+9783qiUAAGAShkx1f+3aNR08eFBFRUWedUFBQVqwYIH279/fo76jo0MdHR2e5aamJklfTYntdDoHv2EAN033Ps2+DfifvuzXhgSUixcvyuVyKS4uzmt9XFycjh8/3qO+uLhYa9eu7bF+165dCg8f2A3AAJhTaWmp0S0A8LHW1tZe1w6JmwUWFRWpsLDQs9zU1KSkpCRlZ2crKirKwM4A+JrT6VRpaamysrK4WSDgZ7qPgPSGIQFl9OjRslqtqqur81pfV1en+Pj4HvWhoaEKDQ31LLvdbklSW1sbX2CAn3E6nWptbVVbW5s6OzuNbgeAD7W1tUn6/7/j38SQgDJs2DDNmDFDu3fvVl5eniSpq6tLu3fv1sqVK7/1+VevXpUkJSUlDWabAABgEFy9elXR0dHfWGPYIZ7CwkI99NBDuvPOO/W9731Pv/nNb9TS0qJHHnnkW5+bmJio8+fPKzIyUhaL5SZ0C+Bm6T6Ee/78eQ7hAn7G7Xbr6tWrSkxM/NZawwLKD37wA124cEHPPfecamtrNW3aNO3cubPHibM3EhQUpLFjx96ELgEYJSoqioAC+KFvGznpZnH35kAQANwkTU1Nio6OVmNjIwEFCGDciwcAAJgOAQWAqYSGhur555/3unIPQODhEA8AADAdRlAAAIDpEFAAAIDpEFAAAIDpEFAADKrMzEw9/fTTg/4+Z86ckcVi0aFDh/5hzd69e2WxWNTQ0DDo/QAYGAIKgD55+OGHZbFY9OSTT/bYVlBQIIvFoocfftizzm6369e//rVP3rP7b9SoUVq4cKEOHz7sqUlKSlJNTY2mTp06oPcCYA4EFAB9lpSUpD/+8Y+eG39JUnt7uzZv3qzk5GSv2tjYWEVGRg74PRcuXKiamhrV1NRo9+7dCg4O1r333uvZbrVaFR8fr+DgIXGTdgDfgoACoM/uuOMOJSUlyW63e9bZ7XYlJydr+vTpXrVfP8Qzfvx4rVu3To8++qgiIyOVnJys3/3ud9/6nqGhoYqPj1d8fLymTZumn//85zp//rwuXLgg6caHeLZv366JEycqLCxM8+bN05kzZwb0uQHcPAQUAP3y6KOP6s033/Qs//73v+/VzT4l6ZVXXtGdd96pTz/9VD/5yU+0YsUKnThxotfv3dzcrLfeekupqakaNWrUDWvOnz+v/Px8LVmyRIcOHdK//Mu/6Oc//3mv3wOAsQgoAPrlwQcf1L59+3T27FmdPXtWf/3rX/Xggw/26rmLFi3ST37yE6Wmpmr16tUaPXq09uzZ843PKSkp0YgRIzRixAhFRkbqv//7v/XOO+8oKOjGX2NvvPGGJkyYoFdeeUW33nqrHnjgAa9zYwCYGwdrAfTLmDFjtHjxYm3atElut1uLFy/W6NGje/Xc2267zfPYYrEoPj5e9fX13/icefPm6Y033pAkXblyRa+//rpyc3N14MABjRs3rkf9sWPHlJ6e7rUuIyOjV/0BMB4BBUC/Pfroo1q5cqUkacOGDb1+XkhIiNeyxWJRV1fXNz4nIiJCqampnuX/+I//UHR0tP793/9dL774Yh+6BjAUcIgHQL8tXLhQ165dk9PpVE5Ozk19b4vFoqCgIK8ria43efJkHThwwGtdRUXFzWgNgA8QUAD0m9Vq1bFjx/TZZ5/JarUO6nt1dHSotrZWtbW1OnbsmJ566ik1NzdryZIlN6x/8skndfLkST377LM6ceKENm/erE2bNg1qjwB8h4ACYECioqIUFRU16O+zc+dOJSQkKCEhQenp6fr444/17rvvKjMz84b1ycnJeu+997Rt2zbdfvvt2rhxo9atWzfofQLwDYvb7XYb3QQAAMD1GEEBAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACmQ0ABAACm838BJOOrUusZYsEAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.boxplot(column=['Min Bid'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "a03179f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 'After Process Vacancy' column as it is future dependent.\n",
    "data = data.drop(columns=['After Process Vacancy'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f6bf3f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Term                       object\n",
       "Description                object\n",
       "Section                    object\n",
       "Vacancy                     int64\n",
       "Before Process Vacancy      int64\n",
       "Median Bid                float64\n",
       "Min Bid                   float64\n",
       "Instructor                 object\n",
       "Grading Basis              object\n",
       "class1_day                 object\n",
       "class1_starttime           object\n",
       "class1_venue               object\n",
       "class2_day                 object\n",
       "class2_starttime           object\n",
       "class2_venue               object\n",
       "class3_day                 object\n",
       "class3_starttime           object\n",
       "class3_venue               object\n",
       "exam_startdate             object\n",
       "exam_day                   object\n",
       "exam_starttime             object\n",
       "AY                          int64\n",
       "Incoming Freshman          object\n",
       "Incoming Exchange          object\n",
       "Round                      object\n",
       "Window                      int64\n",
       "SubjectArea                object\n",
       "CatalogueNo                object\n",
       "dtype: object"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b0498",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 4. Save data into CSV\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ce35bda4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to transformed_data_w_timings_v3.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the transformed data to a CSV file\n",
    "output_path = 'transformed_data_w_timings_v3.csv'\n",
    "data.to_csv(output_path, index=False)\n",
    "print(f\"Data successfully saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BidlyEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
